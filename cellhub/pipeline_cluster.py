"""=============
Pipeline cluster
================

Overview
========

This pipeline performs clustering of integrated single cell data.

Usage
=====

See :doc:`Installation</Installation>` and :doc:`Usage</Usage>` on general
information how to use CGAT pipelines.

Configuration
-------------

It is recommended to perform the clustering in a new directory.

The pipeline requires a configured :file:`pipeline_cluster.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_cluster.py config


Inputs
------

The pipeline starts from an anndata object with the following structure.

* anndata.X -> scaled data
* anndata.layers["counts"] -> raw counts
* anndata.layers["log1p"] -> total count normalised, 1og1p transformed data
* anndata.obs -> metadata (typically passed through from original cellhub object)
* anndata.obsm["X_rdim_name"] -> where "rdim_name" matches the "runspec_rdim_name" parameter

It is strongly recommended to retain the information for all of the genes
in all of the matrices (i.e. do not subset to HVGs!)

Dependencies
------------

This pipeline requires:


Pipeline output
===============

The pipeline produces the following outputs:


"""

import os
import sys
import gzip
from shutil import copyfile

from pathlib import Path
import pandas as pd
import yaml
import textwrap
from ruffus import *
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

import cellhub.tasks.control as C
import cellhub.tasks.fetch_cells as fetch_cells
import cellhub.tasks.TASK as TASK
import cellhub.tasks.templates as templates

# Override function to collect config files
P.control.write_config_files = C.write_config_files


# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline_cluster.yml" % os.path.splitext(__file__)[0],
     "../pipeline_cluster.yml",
     "pipeline_cluster.yml"])

# set the location of the code directory
PARAMS["cellhub_code_dir"] = Path(__file__).parents[1]


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))

# ------------------------------ < functions > ------------------------------ #

# ########################################################################### #
# ############################# pipeline tasks ############################## #
# ########################################################################### #

@files(None, "task.summary.table.tex")
def taskSummary(infile, outfile):
    '''Make a summary of optional tasks that will be run'''

    tasks, run = [], []

    for k,v in PARAMS.items():
        if k.startswith("run_"):
            tasks.append(k[4:])
            run.append(str(v))

    tab = pd.DataFrame(list(zip(tasks,run)),columns=["task","run"])
    print(tab)

    tab.to_latex(buf=outfile, index=False)


@files(PARAMS["source_anndata"],
       "metadata.dir/metadata.sentinel")
def metadata(infile, outfile):
    '''
       Export the metadata (obs) from the source anndata
       for use in the plotting tasks
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"], PARAMS=PARAMS)

    outfile_name = outfile.replace(".sentinel", ".tsv.gz")

    statement = '''python %(cellhub_code_dir)s/python/cluster_metadata.py
                   --source_anndata=%(infile)s
                   --outfile=%(outfile_name)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

# ########################################################################### #
# ###################### Compute the neighbor graph ######################### #
# ########################################################################### #

def genNeighbourGraphs():

    components_str = str(PARAMS["runspecs_n_components"])
    components = components_str.strip().replace(" ", "").split(",")

    outname = "neighbour.graph.sentinel"

    infile = PARAMS["source_anndata"]

    for comps in components:

        outdir = "out." + comps + ".comp.dir"

        outfile = os.path.join(outdir, outname)
        yield [infile, outfile]


@files(genNeighbourGraphs)
def neighbourGraph(infile, outfile):
    '''
       Compute the neighbor graph.

       A miniminal anndata is saved for UMAP computation and clustering
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    print(SPEC)

    reductiontype = PARAMS["dimreduction_method"]

    #SPEC["components"] = outfile.split("/")[1][len("components."):-len(".dir")]

    ncomps = spec.components

    # set the job threads and memory
    if PARAMS["neighbors_full_speed"]:
        full_speed = "--fullspeed"
    else:
        full_speed = ""

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"], PARAMS=PARAMS)

    outfile_name = outfile.replace(".sentinel", ".h5ad")

    statement = '''python %(cellhub_code_dir)s/python/cluster_neighbor_graph.py
                   --source_anndata=%(infile)s
                   --reduced_dims_name=%(source_rdim_name)s
                   --outfile=%(outfile_name)s
                   --ncomps=%(ncomps)s
                   --method=%(neighbors_method)s
                   --threads=%(neighbors_threads)s
                   --k=%(neighbors_n_neighbors)s
                   --metric=%(neighbors_metric)s
                   %(full_speed)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ############################ Clustering ################################### #
# ########################################################################### #

def genScanpyClusterJobs():

    components_str = str(PARAMS["runspecs_n_components"])
    components = components_str.strip().replace(" ", "").split(",")

    if PARAMS["runspecs_cluster_resolutions"]:
        resolutions = [ x.strip() for x in
                        str(PARAMS["runspecs_cluster_resolutions"]).split(",") ]

    outname = "scanpy.clusters.sentinel"

    for comps in components:

        outdir = "out." + comps + ".comp.dir"
        infile = os.path.join(outdir,
        "neighbour.graph.h5ad")

        if PARAMS["runspecs_predefined_clusters"] :

            subdir = "cluster.predefined.dir"
            outfile = os.path.join(outdir, subdir, outname)
            yield [infile, outfile]

        if PARAMS["runspecs_cluster_resolutions"]:
            for resolution in resolutions:

                subdir = "cluster." + resolution + ".dir"
                outfile = os.path.join(outdir, subdir, outname)
                yield [infile, outfile]


@follows(neighbourGraph)
@files(genScanpyClusterJobs)
def scanpyCluster(infile, outfile):
    '''
       discover clusters using scanpy.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"])

    if not "cluster.predefined.dir" in spec.outdir:

        statement = '''python %(cellhub_code_dir)s/python/cluster_cluster.py
                   --anndata=%(infile)s
                   --algorithm=%(cluster_algorithm)s
                   --resolution=%(resolution)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

        P.run(statement)

    IOTools.touch_file(outfile)


@transform(scanpyCluster,
           regex(r"(.*)/scanpy.clusters.sentinel"),
           r"\1/cluster.sentinel")
def cluster(infile, outfile):
    '''
    post-process the clustering result
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    scanpy_cluster_tsv = infile.replace(".sentinel",".tsv.gz")

    if "cluster.predefined.dir"  in spec.indir:
        predefined='--predefined=' + PARAMS["runspecs_predefined_clusters"]
    else:
        predefined=""

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_post_process.R
                   --clusters=%(scanpy_cluster_tsv)s
                   %(predefined)s
                   --mincells=10
                   --outdir=%(outdir)s
                   > %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_compare_clusters"])
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/compare.clusters.sentinel")
def compareClusters(infile, outfile):
    '''Draw a dendrogram showing the relationship between the clusters
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    reductiontype = PARAMS["source_rdim_name"]

    if spec.resolution == "predefined":

        # TODO: Fix.
        cluster_file = sample + ".cluster_ids.rds"

        if os.path.exists(cluster_file):
            predefined = "--predefined=%(cluster_file)s" % locals()

        else:
            raise ValueError("Predefined cluster assignment file (%(cluster_file)s) not found" % locals())

    else:
        predefined = ""

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    statement = '''python %(cellhub_code_dir)s/python/cluster_compare.py
                   --source_anndata=%(source_anndata)s
                   --clusterids=%(cluster_ids)s
                   --ncomp=%(components)s
                   --outdir=%(outdir)s
                   --reduced_dims_name=%(reductiontype)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ############### compare the clusters across resolutions ################### #
# ########################################################################### #

nresolutions = len(str(PARAMS["runspecs_cluster_resolutions"]).split(","))

@active_if(nresolutions > 1)

@follows(cluster)
@transform(neighbourGraph,
           regex(r"(.*)/neighbour.graph.sentinel"),
           r"\1/clustree.sentinel")
def clustree(infile, outfile):
    '''
       Run clustree.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    id_files = [ os.path.join(spec.outdir,
                              "cluster." + r + ".dir",
                              "cluster_ids.tsv.gz")
                 for r in spec.resolutions ]

    res_str = ",".join(spec.resolutions)
    id_files_str = ",".join(id_files)

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_clustree.R
                   --resolutions=%(res_str)s
                   --clusteridfiles=%(id_files_str)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_paga"])
@follows(neighbourGraph)
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/paga.dir/paga.sentinel")
def paga(infile, outfile):
    '''
       Run partition-based graph abstraction (PAGA)
       see: https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1663-x
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_high"])

    statement = '''python %(cellhub_code_dir)s/python/cluster_paga.py
                   --anndata=%(neighbour_graph_anndata)s
                   --outdir=%(outdir)s
                   --cluster_ids=%(cluster_ids)s
                   --cluster_colors=%(cluster_colors)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ############### UMAP analysis and related plots ########################### #
# ########################################################################### #

@transform(neighbourGraph,
           regex(r"(.*)/neighbour.graph.sentinel"),
           r"\1/umap.dir/umap.sentinel")
def UMAP(infile, outfile):
    '''
    Run the UMAP analysis on a saved anndata object.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_high"],
        cpu=2)

    mindists = [x.strip() for x in PARAMS["umap_mindists"].split(",")]

    statements = []
    for mindist in mindists:

        mindist_log_file = outfile.replace(".sentinel",
                                           "." + mindist + ".log")

        statement = '''python %(cellhub_code_dir)s/python/cluster_umap.py
                             --anndata=%(neighbour_graph_anndata)s
                             --mindist=%(mindist)s
                             --outdir=%(outdir)s
                             &> %(mindist_log_file)s
                     ''' % dict(PARAMS, **SPEC, **locals())

        statements.append(statement)

    P.run(statements)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ####################### Known gene violin plots ########################### #
# ########################################################################### #

@files(None,None)
def knownMarkerViolins(infile, outfile):
    pass

# @active_if(PARAMS["run_knownmarkers"])
# @transform(scanpyCluster,
#            regex(r"(.*)/(.*)/(.*)/cluster.sentinel"),
#            r"\1/\2/\3/known.markers.dir/known.markers.sentinel")
# def knownMarkerViolins(infile, outfile):
#     '''
#        Make per-cluster violin plots from a given set of known marker genes.
#     '''

#     spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

#     if not os.path.exists(PARAMS["knownmarkers_file"]):
#         raise ValueError("The specified known markers file does not exist")

#     outprefix = outfile.replace(".sentinel", "")

#     # set the job threads and memory
#     job_threads, job_memory, r_memory = TASK.get_resources(
#         memory=PARAMS["resources_memory_low"])

#     statement = '''Rscript %(cellhub_code_dir)s/R/plot_violins.R
#                        --genetable=%(knownmarkers_file)s
#                        --seuratobject=%(seurat_object)s
#                        --seuratassay=RNA
#                        --clusterids=%(cluster_ids)s
#                        --outprefix=%(outprefix)s
#                        --plotdirvar=knownmarkersDir
#                        &> %(log_file)s
#         ''' % dict(PARAMS, **SPEC, **locals())

#     P.run(statement)
#     IOTools.touch_file(outfile)


# ########################################################################### #
# ################## Set the DR visualisation method ######################## #
# ########################################################################### #

# Used to show clusters, factors of interest and gene expression levels
# in various downstream functions

RDIMS_VIS_TASK = UMAP
RDIMS_VIS_METHOD = "umap"
RDIMS_VIS_COMP_1 = "UMAP_1"
RDIMS_VIS_COMP_2 = "UMAP_2"


# ########################################################################### #
# ###### Visualise gene expression across cells in reduced dimensions ####### #
# ########################################################################### #

@transform(RDIMS_VIS_TASK,
           regex(r"(.*)/(.*)/(.*).sentinel"),
           add_inputs(metadata),
           r"\1/rdims.visualisation.dir/plot.rdims.factor.sentinel")
def plotRdimsFactors(infiles, outfile):
    '''
    Visualise factors of interest on the projection.
    '''

    infile, export_sentinel = infiles

    metadata_table = os.path.join(os.path.dirname(export_sentinel),
                                  "metadata.tsv.gz")

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    rdims_table = infile.replace(".sentinel",
                                 "." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

    color_factors = []

    if PARAMS["plot_qcvars"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_qcvars"].split(",")]

    if PARAMS["plot_groups"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_groups"].split(",")]

    if PARAMS["plot_subgroup"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_subgroup"].split(",")]

    color_factors = [ x for x in color_factors if x != "cluster" ]

    # ensure list is unique whilst preserving order.
    color_factors = list(dict.fromkeys(color_factors))

    color_factors = "--colorfactors=" + ",".join(color_factors)

    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    # bring vars into local scope..
    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_rdims_factor.R
                   --method=%(rdims_vis_method)s
                   --table=%(rdims_table)s
                   --metadata=%(metadata_table)s
                   --rdim1=%(rdim1)s
                   --rdim2=%(rdim2)s
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --pointpch=%(plot_pointpch)s
                   --pdf=%(plot_pdf)s
                   --outdir=%(outdir)s
                   --plotdirvar=rdimsVisFactorDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)

    tex_file = os.path.join(spec.outdir, "plot.rdims.factor.tex")

    with open(tex_file, "w") as tex:
        tex.write("\input{" + os.path.join(spec.outdir) + "/umap}")

    IOTools.touch_file(outfile)


@follows(RDIMS_VIS_TASK)
@transform(cluster,
           regex(r"(.*)/(.*)/(.*).sentinel"),
           r"\1/\2/rdims.visualisation.dir/plot.rdims.cluster.sentinel")
def plotRdimsClusters(infile, outfile):
    '''
    Visualise the clusters on the chosen projection
    '''

    metadata_table = os.path.join(os.path.dirname(infile),
                                  "cluster_ids.tsv.gz")

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    print("******")
    print(spec)

    color_factors = "--colorfactors=cluster_id"

    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    # bring vars into local scope..
    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])


    mindists = [x.strip() for x in PARAMS["umap_mindists"].split(",")]

    statements = []
    for mindist in mindists:

        rdims_table = os.path.join(spec.component_dir,
                                   "umap.dir",
                                   "umap." + mindist + ".tsv.gz")

        umap_spec = "umap.mindist_" + mindist

        mindist_log_file = outfile.replace(".sentinel",
                                           "." + mindist + ".log")

        statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_rdims_factor.R
                   --method=%(umap_spec)s
                   --table=%(rdims_table)s
                   --metadata=%(metadata_table)s
                   --rdim1=%(rdim1)s
                   --rdim2=%(rdim2)s
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --pointpch=%(plot_pointpch)s
                   --pdf=%(plot_pdf)s
                   --outdir=%(outdir)s
                   --plotdirvar=rdimsVisClusterDir
                   &> %(mindist_log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

        statements.append(statement)
    P.run(statements)

    tex_file = os.path.join(spec.outdir, "plot.rdims.factor.tex")

    with open(tex_file, "w") as tex:
        for mindist in mindists:
            tex.write("\input{" + spec.outdir + "/umap.mindist_" + mindist + "}\n")

    IOTools.touch_file(outfile)


@files(None, None)
def singleR(infile, outfile):
    '''dummy function while refactoring'''
    pass

# Fix
@active_if(PARAMS["run_singleR"])
@transform(singleR,
           formatter("(.sentinel)$"),
           "{path[0]}/"
           "{basename[0]}.plot.sentinel")
def plotSingleR(infile, outfile):
    '''Make the singleR heatmap'''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    predictions = os.path.join(spec.indir,
                               "predictions.rds")

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"])

    statement = '''Rscript %(cellhub_code_dir)s/R/singleR_plots.R
                       --seuratobject=%(seurat_object)s
                       --predictions=%(predictions)s
                       --outdir=%(outdir)s
                       --pdf=%(plot_pdf)s
                       &> %(log_file)s
                       ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

#@follows(UMAP)
@active_if(PARAMS["run_singleR"])
# @product(UMAP,
#          formatter("(.sentinel)$"),
#          singleR,
#          formatter("(.sentinel)$"),
#          "{subpath[0][0][1]}/"         #  cluster files, first file  seurat.dir/comp.dir/cluster.dir/clusters
#          "singleR.dir/"
#          "{subdir[1][0][0]}/"
#          "singleR.umap.sentinel")
@files(None, None)
def plotUmapSingleR(infiles, outfile):
    '''Plot the SingleR primary identity assignments on a UMAP'''

    cluster_sentinel, singleR_sentinel = infiles

    spec, SPEC = TASK.get_vars(cluster_sentinel, outfile, PARAMS)


    singleR_dir = os.path.dirname(singleR_sentinel)

    metadata = os.path.join(singleR_dir, "labels.tsv.gz")

    rdims_table = os.path.join(spec.component_dir,
                               "umap.dir",
                               "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

    # bring vars into local scope..
    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    #outdir = os.path.dirname(outfile)
    #log_file = outfile.replace(".sentinel", ".log")

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"])

    statement  = '''Rscript %(cellhub_code_dir)s/R/plot_rdims_factor.R
                        --method=%(rdims_vis_method)s
                        --table=%(rdims_table)s
                        --metadata=%(metadata)s
                        --rdim1=%(rdim1)s
                        --rdim2=%(rdim2)s
                        --colorfactors=pruned.labels
                        --pointsize=%(plot_pointsize)s
                        --pointalpha=%(plot_pointalpha)s
                        --pointpch=%(plot_pointpch)s
                        --pdf=%(plot_pdf)s
                        --outdir=%(outdir)s
                        --plotdirvar=rdimsVisSingleRDir
                        &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_singleR"])
@follows(plotSingleR, plotUmapSingleR)
@transform(UMAP,
           regex(r"(.*)/umap.dir/umap.sentinel"),
           r"\1/singleR.dir/singleR.summary.tex")
def summariseSingleR(infile, outfile):
    '''Collect the single R plots into a section for the report'''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    references = [x.strip() for x in PARAMS["singleR_reference"].split(",")]

    singleR_path = os.path.join(Path(infile).parents[2],
                                "singleR.dir")

    singleR_umap_path = spec.outdir


    latex_path = outfile  # .replace(".sentinel", ".tex")

    with open(latex_path, "w") as tex:

        for reference in references:

            # heatmap
            tex.write(templates.subsection % {"title": reference})
            tex.write("\n")

            heatmap_path = os.path.join(singleR_path,
                                        reference + ".ref.dir",
                                        "singleR_score_heatmap")


            if(os.path.exists(heatmap_path + ".png")):
                heatmap_fig = {"width": "1", "height": "0.9",
                               "path": heatmap_path,
                               "caption": "singleR predictions (" +\
                               reference + ")"}

                tex.write(textwrap.dedent(
                    templates.figure % heatmap_fig))
                tex.write("\n")

            umap_path = os.path.join(singleR_umap_path,
                                        reference + ".ref.dir",
                                        "umap.pruned.labels")

            # umap
            if(os.path.exists(umap_path + ".png")):

                umap_fig = {"width": "1", "height": "0.9",
                            "path": umap_path,
                            "caption": "pruned singleR predictions (" +\
                            reference + ")"}

                tex.write(textwrap.dedent(
                    templates.figure % umap_fig))

                tex.write("\n")

@follows(RDIMS_VIS_TASK)
@active_if(PARAMS["run_exprsreport"] and not PARAMS["run_marker_report"])
@transform(scanpyCluster,
           regex(r"(.*)/cluster.sentinel"),
           r"\1/genelists.dir/plot.rdims.genes.sentinel")
def plotRdimsGenes(infile, outfile):
    '''
    Visualise gene expression levels on reduced dimension coordinates

    The @data slot of the seurat object is used.
    '''

    # TODO: test and fix.

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    tex_path = os.path.join(spec.outdir, "plot.rdims.known.genes.tex")

    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    rdims_table = os.path.join(spec.component_dir,
                               "umap.dir",
                               "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")


    if PARAMS["exprsreport_genelists"]:
        genelists = glob.glob(
            os.path.join(PARAMS["exprsreport_genelist_dir"], "*.tsv"))

        # if RDIMS_VIS_METHOD == "tsne":
        #     rdims_table = infile.replace(
        #         "sentinel", str(PARAMS["tsne_perplexity"]) + ".tsv")
        # elif RDIMS_VIS_METHOD == "umap":
        rdims_table = infile.replace( ".sentinel", ".tsv")

        # set the job threads and memory
        job_threads, job_memory, r_memory = TASK.get_resources(
            memory=PARAMS["resources_memory_standard"],
            cpu=PARAMS["resources_numcores"])

        for genelist in genelists:

            fname = "plot.rdims.genes." + os.path.basename(genelist) + ".log"
            log_file = os.path.join(outdir, fname)

            if PARAMS["plot_shape"] is not None:
                shape = "--shapefactor=%(plot_shape)s" % PARAMS
            else:
                shape = ""

            statement = '''Rscript %(cellhub_code_dir)s/R/plot_rdims_gene.R
                           --method=%(rdims_vis_method)s
                           --table=%(rdims_table)s
                           --seuratobject=%(seurat_object)s
                           --seuratassay=RNA
                           --rdim1=%(rdim1)s
                           --rdim2=%(rdim2)s
                           %(shape)s
                           --genetable=%(genelist)s
                           --pointsize=%(plot_pointsize)s
                           --pointalpha=%(plot_pointalpha)s
                           --maxcells=%(plot_maxcells)s
                           --outdir=%(outdir)s
                           --pdf=%(plot_pdf)s
                           --plotdirvar=genelistsDir
                           --workers=%(exprsreport_workers)s
                           &> %(log_file)s
                       ''' % dict(PARAMS, **SPEC, **locals())

            P.run(statement)

        # prepare a summary tex snippet for inclusion in the report.

        with(open(tex_path, "w")) as tex:

            for genelist in genelists:

                texf = os.path.join(
                    outdir,
                    "plot.rdims.genes." +
                    os.path.basename(genelist).replace(".tsv", ""))

                gsname = os.path.basename(
                    genelist)[:-len(".tsv")].replace("_", "\\_")

                tex.write(
                    "\\subsection{Expression of known genes: %s}\n" % gsname)
                tex.write(
                    "\\input{%(texf)s}\n" % locals())

            tex.write("\n")

    else:

        with(open(tex_path, "w")) as tex:

            tex.write("No genelists were specified.\n")
            tex.write("\n")

    IOTools.touch_file(outfile)


# ########################################################################### #
# ################# plot per-cluster summary statistics ##################### #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.sentinel"),
           add_inputs(metadata),
           r"\1/group.numbers.dir/plot.group.numbers.sentinel")
def plotGroupNumbers(infiles, outfile):
    '''
    Plot statistics on cells by group, e.g. numbers of cells per cluster.

    Plots are defined on a case-by-case basis in the yaml.
    '''

    cluster_outfile, metadata_outfile = infiles

    spec, SPEC = TASK.get_vars(cluster_outfile, outfile, PARAMS)

    metadata_table = metadata_outfile.replace(".sentinel", ".tsv.gz")

    # we need the yaml as a dict, so...
    config_file = "pipeline_cluster.yml"
    if not os.path.exists(config_file):
        config_file = "%s/pipeline_cluster.yml" % os.path.splitext(__file__)[0]
        if not os.path.exists(config_file):
            raise ValueError("Config file not found in plot group numbers")

    with open(config_file) as f:
        params = yaml.load(f, Loader=yaml.FullLoader)

    params = params["summaries"]

    statements = []
    for summary_key in params.keys():

        summary = params[summary_key].copy()

        options = []

        # populate the Rscript options from the yaml dictionary
        for k, v in summary.items():
            if v == "None" or v == None or v == False or k == "title":
                pass
            elif v == True:
                options.append("--" + k)
            elif k in ["xlab", "ylab"]:
                options.append("--" + k + "=\"" + str(v) + "\"")
            else:
                options.append("--" + k + "=" + str(v))

        options = "\n".join(options)

        SPEC["log_file"] = os.path.join(spec.outdir, summary_key + ".log")

        job_threads, job_memory, r_memory = TASK.get_resources(
            memory=PARAMS["resources_memory_min"])

        statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_group_numbers.R
                   --metadata=%(metadata_table)s
                   --clusters=%(cluster_ids)s
                   --title=%(summary_key)s
                   %(options)s
                   --outdir=%(outdir)s
                   --plotdirvar=groupNumbersDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

        statements.append(statement)

    P.run(statements)

    # write out the latex snippet...
    with open(os.path.join(spec.outdir, "number.plots.tex"),"w") as tex:

        for fig in params.keys():

            if("_" in params[fig]["title"]):
               raise ValueError("Underscores are not allowed in the plot"
                                " titles (due to issues with latex...")

            # Add the figures, one per subsection, escaping underscores.
            tex.write(templates.subsection %
                      {"title": params[fig]["title"]})

            tex.write("\n")

            fig_path = os.path.join(spec.outdir, fig)

            if(os.path.exists(fig_path + ".png")):
                fig_spec = {"width": "1", "height": "0.9",
                            "path": fig_path,
                            "caption": params[fig]["title"]
                            }

                tex.write(textwrap.dedent(
                    templates.figure % fig_spec))
                tex.write("\n")

    IOTools.touch_file(outfile)

# ########################################################################### #
# ############# Cluster marker identification and visualisation ############# #
# ########################################################################### #

# @follows(getGenesetAnnotations)
@transform(cluster,
           regex(r"(.*)/cluster.sentinel"),
           r"\1/cluster.markers.dir/findMarkers.sentinel")
def findMarkers(infile, outfile):
    '''
    Identification of cluster marker genes.

    This analysis is run in parallel for each cluster.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    if PARAMS["findmarkers_conserved"]:
        conservedfactor = PARAMS["findmarkers_conserved_factor"]
        conservedpadj = PARAMS["findmarkers_conserved_padj"]
        conserved_options = '''--conservedfactor=%(conservedfactor)s
            --conservedpadj=%(conservedpadj)s
        '''
    else:
        conserved_options = ""

    statements = []

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"],
        cpu=PARAMS["findmarkers_numcores"])

    for i in spec.clusters:

        if str(i) == "911":
            continue

        SPEC["log_file"] = outfile.replace(".sentinel", "." + str(i) + ".log")

        statements.append('''Rscript %(cellhub_code_dir)s/R/seurat_FindMarkers.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --clusterids=%(cluster_ids)s
                   --cluster=%(i)s
                   --testuse=%(findmarkers_test)s
                   --minpct=%(findmarkers_minpct)s
                   --mindiffpct=-Inf
                   --maxcellsperident=%(findmarkers_maxcellsperident)s
                   --threshuse=%(findmarkers_threshuse)s
                   %(conserved_options)s
                   --annotation=annotation.dir/ensembl.to.entrez.tsv.gz
                   --numcores=%(findmarkers_numcores)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals()))

    P.run(statements)
    IOTools.touch_file(outfile)


@transform(scanpyCluster,
           regex(r"(.*)/cluster.sentinel"),
           r"\1/cluster.markers.dir/cluster.stats.sentinel")
def clusterStats(infile, outfile):
    '''
    Computation of per-cluster statistics

    This analysis is run in parallel for each cluster.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    if PARAMS["findmarkers_conserved"]:
        conservedfactor = PARAMS["findmarkers_conserved_factor"]
        conserved_options = '''--conservedfactor=%(conservedfactor)s
        '''
    else:
        conserved_options = ""

    statements = []

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"],
        cpu=1)

    for i in spec.clusters:

        if str(i) == "911":
            continue

        SPEC["log_file"] = outfile.replace(".sentinel", "." + str(i) + ".log")

        statements.append('''Rscript %(cellhub_code_dir)s/R/seurat_clusterStats.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --clusterids=%(cluster_ids)s
                   --cluster=%(i)s
                   %(conserved_options)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals()))

    P.run(statements)
    IOTools.touch_file(outfile)


@transform(clusterStats,
           regex(r"(.*)/cluster.stats.sentinel"),
           r"\1/summarise.stats.sentinel")
def summariseClusterStats(infile, outfile):
    '''
    Make summary tables of the cluster stats.

    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"],
        cpu=1)

    # make sumamary tables and plots of the differentially expressed genes
    statement = '''Rscript %(cellhub_code_dir)s/R/summarise_clusterStats.R
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@follows(summariseClusterStats)
@transform(findMarkers,
           regex(r"(.*)/findMarkers.sentinel"),
           r"\1/summariseMarkers.sentinel")
def summariseMarkers(infile, outfile):
    '''
    Make summary tables and plots of cluster marker genes.

    The per-cluster results files are aggregated.  Asummary excel
    file is generated. Tables for geneset enrichment testing
    are prepared.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    cluster_stats_table = os.path.join(spec.outdir,
                                       "cluster.stats.summary.table.tsv.gz")

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"],
        cpu=1)

    # make sumamary tables and plots of the differentially expressed genes
    statement = '''Rscript %(cellhub_code_dir)s/R/seurat_summariseMarkers.R
                   --seuratobject=%(seurat_object)s
                   --statstable=%(cluster_stats_table)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)

    IOTools.touch_file(outfile)


@active_if(PARAMS["run_top_marker_heatmap"])
@transform(summariseMarkers,
           regex(r"(.*)/summariseMarkers.sentinel"),
           r"\1/topMarkerHeatmap.sentinel")
def topMarkerHeatmap(infile, outfile):
    '''
    Characterise cluster marker genes.

    Diagnostic summary plots of differentially expressed genes
    and violin plots of cluster marker gene expression are generated.

    Parallelised per-cluster.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.tsv.gz")


    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"],
        cpu=1)

    if PARAMS["plot_subgroup"] is not None:
        subgroup = '''--subgroup=%(plot_subgroup)s''' % PARAMS
    else:
        subgroup = ""

    statement = '''
    Rscript %(cellhub_code_dir)s/R/seurat_topMarkerHeatmap.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --slot=%(findmarkers_heatmap_slot)s
                   --markers=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --pdf=%(plot_pdf)s
                   %(subgroup)s
                   --outdir=%(outdir)s
                    &> %(log_file)s
                    ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_characterise_markers"])
@transform(summariseMarkers,
           regex(r"(.*)/cluster.markers.dir/summariseMarkers.sentinel"),
           r"\1/cluster.marker.de.plots.dir/characteriseClusterMarkers.tex")
def characteriseClusterMarkers(infile, outfile):
    '''
    Characterise cluster marker genes.

    Diagnostic summary plots of differentially expressed genes
    and violin plots of cluster marker gene expression are generated.

    Parallelised per-cluster.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.tsv.gz")

    # not all clusters may have degenes
    degenes = pd.read_csv(marker_table, sep="\t")

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"],
        cpu=1)

    statements = []
    tex = []

    for i in spec.clusters:

        if str(i) == "911":
            continue

        SPEC["log_file"] = outfile[:-len(".tex")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(cellhub_code_dir)s/R/seurat_characteriseClusterDEGenes.R
                    --degenes=%(marker_table)s
                    --seuratobject=%(seurat_object)s
                    --seuratassay=RNA
                    --clusterids=%(cluster_ids)s
                    --cluster=%(i)s
                    --outdir=%(outdir)s
                    --useminfc=TRUE
                    --pointsize=%(plot_vpointsize)s
                    --ncol=%(plot_vncol)s
                    --nrow=%(plot_vnrow)s
                    --pdf=%(plot_pdf)s
                    --plotdirvar=clusterMarkerDEPlotsDir
                    &> %(log_file)s
                    ''' % dict(PARAMS, **SPEC, **locals())

        cluster_tex_file = ".".join(["characterise.degenes", str(i), "tex"])
        tex.append("\\input{\\clusterMarkerDEPlotsDir/" + cluster_tex_file + "}")
        statements.append(statement)

    P.run(statements)

    with open(outfile, "w") as out_tex:
        for line in tex:
            out_tex.write(line + "\n")


@active_if(PARAMS["run_extra_cluster_marker_plots"])
@transform(summariseMarkers,
           regex(r"(.*)/cluster.markers.dir/summariseMarkers.sentinel"),
           r"\1/cluster.marker.extra.plots.dir/cluster.marker.plots.sentinel")
def extraClusterMarkerPlots(infile, outfile):
    '''
       Make an additional set of per marker plots
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.tsv.gz")

    # not all clusters may have degenes
    markers = pd.read_csv(marker_table, sep="\t")
    clusters_with_markers = [x for x in markers.cluster.unique()]

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"],
        cpu=1)

    statements = []

    # bring vars into local scope..
    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    rdims_table = os.path.join(spec.component_dir,
                               "umap.dir",
                               "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

    if PARAMS["plot_subgroup"] is not None:
        group_opt = "--group=" + PARAMS["plot_subgroup"]
    else:
        group_opt = ""

    for i in clusters_with_markers:

        if str(i) == "911":
            continue

        SPEC["log_file"] = outfile[:-len(".sentinel")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(cellhub_code_dir)s/R/seurat_cluster_marker_plots.R
                    --markers=%(marker_table)s
                    --seuratobject=%(seurat_object)s
                    --seuratassay=RNA
                    --clusterids=%(cluster_ids)s
                    --rdimstable=%(rdims_table)s
                    --rdim1=%(rdim1)s
                    --rdim2=%(rdim2)s
                    --cluster=%(i)s
                    --outdir=%(outdir)s
                    %(group_opt)s
                    --pdf=%(plot_pdf)s
                    &> %(log_file)s
                    ''' % dict(PARAMS, **SPEC, **locals())

        statements.append(statement)

    P.run(statements)

    IOTools.touch_file(outfile)



@transform(summariseMarkers,
           regex(r"(.*)/cluster.markers.dir/(.*).sentinel"),
           r"\1/cluster.marker.de.plots.dir/plotMarkerNumbers.sentinel")
def plotMarkerNumbers(infile, outfile):
    '''
    Summarise the numbers of per-cluster marker genes.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.tsv.gz")

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    statement = '''Rscript %(cellhub_code_dir)s/R/seurat_summariseMarkerNumbers.R
                   --degenes=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   --minfc=2
                   --minpadj=0.05
                   --plotdirvar=clusterMarkerDEPlotsDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)



@active_if(PARAMS["run_exprsreport"])
@follows(summariseMarkers)
@transform(scanpyCluster,
           regex(r"(.*)/cluster.sentinel"),
           r"\1/cluster.marker.rdims.plots.dir/top.cluster.markers.sentinel")
def topClusterMarkers(infile, outfile):
    '''
    Identify the strongest cluster markers
    based on significance, expression frequency, expression level
    and fold change.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_summary_file = os.path.join(spec.cluster_dir,
                                       "cluster.markers.dir",
                                       "markers.summary.table.tsv.gz")

    data = pd.read_csv(marker_summary_file, sep="\t")

    def _filterAndScore(data):
        # filter for strong cluster markers
        data = data[(data["p.adj"] < 0.01) &
                    (data["avg_logFC"].abs() > np.log(2)) &
                    (data["cluster_mean"] > 2) &
                    (data["pct.1"] > 0.25)]

        # compute a score based on all factors of interest.
        # here we use the product of the rank-normalised values
        # for fold change, expression level and adjusted p-value.
        # the aim is to give "better" markers higher scores.
        pscore = [1 - x for x in data["p.adj"].values]
        fscore = [np.exp(np.abs(x)) for x in data["avg_logFC"].values]
        escore = [np.log2(x) for x in data["cluster_mean"].values]

        # construct a matrix of the scores and take the geometric mean.
        temp = np.matrix([pscore,
                          fscore,
                          escore])

        data["score"] = np.squeeze(np.asarray(gmean(temp)))

        # keep only the best record for each gene
        # July 2020 - keep all so that we can see the combinations
        #             of markers for each cluster.
        # data = data.sort_values(["score"], ascending=False)
        # data = data.drop_duplicates(subset="gene_id", keep="first")

        # re-sort by cluster and then score
        data = data.sort_values(["cluster", "score"], ascending=[True, False])

        return data

    # define some helper functions..
    def _skimMarkers(data, n=40):
        # ensure we are ranked by cluster and score, best genes first.
        data = data.sort_values(["cluster", "score"], ascending=[True, False])

        # add the per cluster rankings
        data["grank"] = data.groupby(["cluster"]).cumcount()+1

        # de-duplicate keeping the marker for the cluster where
        # it has the best ranking.
        data = data.sort_values(["grank"], ascending=True)
        data = data.drop_duplicates(subset="gene_id", keep="first")

        # reorder and take the n best markers per cluster.
        data = data.sort_values(["cluster", "score"], ascending=[True, False])
        data = data.groupby("cluster").head(n)

        return data

    def _addGeneName(d):
        d["gene_name"] = d["gene"] + " (" + d["type"] + "; cluster " + \
                         d["cluster"].astype(str) + ")"
        return d

    def _write_tables(d, name="none"):

        # write the markers out to a table
        file_name = ".".join(["top", name, "cluster.markers.tsv"])
        markers_file = os.path.join(spec.outdir, file_name)
        d.to_csv(markers_file, header=True, sep="\t")

        log_name = ".".join(["plot.rdims.top", name, "cluster.markers.log"])
        SPEC["log_file"] = os.path.join(spec.outdir, log_name)

        if(d.shape[0] > 0):

            assay_file = markers_file.replace(".tsv",".rds")

            job_threads, job_memory, r_memory = TASK.get_resources(
                memory=PARAMS["resources_memory_standard"])


            statement = '''Rscript %(cellhub_code_dir)s/R/seurat_get_assay_data.R
                           --seuratobject=%(seurat_object)s
                           --seuratassay=RNA
                           --slot=data
                           --features=%(markers_file)s
                           --outfile=%(assay_file)s
                           &> %(log_file)s
                       ''' % dict(PARAMS, **SPEC, **locals())
            return statement

        else:
            with(open(os.path.join(spec.outdir, "plot.rdims.genes.top." + name +
                                   ".cluster.markers.tex"), "w")) as tex:

                tex.write("No marker genes passed criteria for plotting\n")

            return False

    # keep up to n entries per cluster
    # note that groupby preserves the ordering.
    positive_markers = data[data["avg_logFC"] > 0]
    positive_markers = _filterAndScore(positive_markers)
    positive_markers = _skimMarkers(positive_markers,
                                    PARAMS["exprsreport_n_positive"])
    positive_markers["type"] = "+ve"
    positive_markers = _addGeneName(positive_markers)
    stat = _write_tables(positive_markers, "positive")

    statements = []
    if stat:
        statements.append(stat)

    negative_markers = data[data["avg_logFC"] < 0]
    negative_markers = _filterAndScore(negative_markers)
    negative_markers = _skimMarkers(negative_markers,
                                    PARAMS["exprsreport_n_negative"])
    negative_markers["type"] = "-ve"
    negative_markers = _addGeneName(negative_markers)
    stat = _write_tables(negative_markers, "negative")

    if stat:
        statements.append(stat)

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_high"])

    P.run(statements)

    IOTools.touch_file(outfile)



@active_if(PARAMS["run_exprsreport"])
@follows(summariseMarkers, RDIMS_VIS_TASK)
@transform(topClusterMarkers,
           regex(r"(.*)/top.cluster.markers.sentinel"),
           r"\1/plot.rdims.markers.sentinel")
def plotRdimsMarkers(infile, outfile):
    '''
    Visualise expression of discovered markers on rdims plots.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    def _plot(marker_table, assay_data, name):

        rdims_vis_method = RDIMS_VIS_METHOD
        rdim1 = RDIMS_VIS_COMP_1
        rdim2 = RDIMS_VIS_COMP_2
        rdims_table = os.path.join(spec.component_dir,
                                   "umap.dir",
                                   "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

        if PARAMS["plot_shape"] != "":
            shape = "--shapefactor=%(plot_shape)s" % PARAMS
        else:
            shape = ""

        statements = []
        markers = pd.read_csv(marker_table, sep="\t")

        name = "plot.rdims.genes.top." + name

        for cluster in markers.cluster.unique():

            if str(cluster) == "911":
                continue

            clog_file = spec.log_file.replace(".log",
                                              "." + name + "." + str(cluster) + ".log")

            statement = '''Rscript %(cellhub_code_dir)s/R/plot_rdims_cluster_genes.R
                           --method=%(rdims_vis_method)s
                           --table=%(rdims_table)s
                           --assaydata=%(assay_data)s
                           --rdim1=%(rdim1)s
                           --rdim2=%(rdim2)s
                           %(shape)s
                           --name=%(name)s
                           --genetable=%(marker_table)s
                           --cluster=%(cluster)s
                           --pointsize=%(plot_pointsize)s
                           --pointalpha=%(plot_pointalpha)s
                           --pointpch=%(plot_pointpch)s
                           --maxcells=%(plot_maxcells)s
                           --outdir=%(outdir)s
                           --pdf=%(plot_pdf)s
                           &> %(clog_file)s
                       ''' % dict(PARAMS, **SPEC, **locals())

            statements.append(statement)

        return statements

    def _tex(marker_table, tex_file, name="markers_genes"):

        markers = pd.read_csv(marker_table, sep="\t")

        with open(tex_file,"w") as tex:

            for cluster in [x for x in markers.cluster.unique()]:

                if str(cluster) == "911":
                    continue

                npages = math.ceil(markers[
                    markers["cluster"]==cluster].shape[0] / 9)

                for page in list(range(1,int(npages)+1)):

                    page_title = "Cluster " + str(cluster)
                    page_title += ": " + name + " marker genes"

                    if page > 1:
                        page_title += " (continued)"

                    tex.write(templates.subsection % {"title": page_title})
                    tex.write("\n")

                    plot_name = "plot.rdims.genes.top." + name + ".cluster." +\
                                str(cluster) + ".page." + str(page)

                    plot_path = os.path.join(os.path.dirname(marker_table),
                                             plot_name)

                    heatmap_fig = {"width": "1", "height": "0.9",
                                   "path": plot_path,
                                   "caption": page_title
                                   }
                    tex.write(textwrap.dedent(
                        templates.figure % heatmap_fig))
                    tex.write("\n")


    positive_markers = os.path.join(spec.outdir,
                                    "top.positive.cluster.markers.tsv")
    positive_data = positive_markers.replace(".tsv", ".rds")
    pstats = _plot(positive_markers, positive_data, "positive")


    negative_markers = os.path.join(spec.outdir,
                                    "top.negative.cluster.markers.tsv")
    negative_data = negative_markers.replace(".tsv", ".rds")
    nstats = _plot(negative_markers, negative_data, "negative")


    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    P.run( pstats + nstats )

    # write out the latex snippets
    positive_tex = os.path.join(spec.outdir,
                                "top.positive.cluster.markers.tex")
    _tex(positive_markers, positive_tex, "positive")

    negative_tex = os.path.join(spec.outdir,
                                "top.negative.cluster.markers.tex")
    _tex(negative_markers, negative_tex, "negative")



    IOTools.touch_file(outfile)



# ########################################################################### #
# ################# Within cluster between condition DE ##################### #
# ########################################################################### #

# Here genes differentially expressed between two conditions are identified
# at the cluster level.
#
# This analysis is optional.
#
# It is only run on samples prefixed with "all.", "agg." or "aligned."

@active_if(PARAMS["findmarkers_between"])
#@follows(getGenesetAnnotations)
@transform(scanpyCluster,
           regex(r"(all.*|agg.*|aligned.*|integrated.*)/cluster.sentinel"),
           r"\1/condition.markers.dir/findMarkersBetweenConditions.sentinel")
def findMarkersBetweenConditions(infile, outfile):
    '''
    Identification of genes differentially expressed within-cluster.

    The two conditions to compare must be specified in the configuration file.

    This analysis is run in parallel for each cluster.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    statements = []

    if PARAMS["findmarkers_conserved_between"]:
        conservedfactor = PARAMS["findmarkers_conserved_between_factor"]
        conservedpadj = PARAMS["findmarkers_conserved_between_padj"]
        conserved_options = '''--conservedfactor=%(conservedfactor)s
            --conservedpadj=%(conservedpadj)s
        '''
    else:
        conserved_options = ""

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"],
        cpu=PARAMS["findmarkers_numcores"])

    for i in spec.clusters:

        if str(i) == "911":
            continue

        cluster_log_file = outfile.replace(".sentinel", "." + str(i) + ".log")
        statements.append('''Rscript %(cellhub_code_dir)s/R/seurat_FindMarkers.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --clusterids=%(cluster_ids)s
                   --cluster=%(i)s
                   --testfactor=%(findmarkers_between_testfactor)s
                   --a=%(findmarkers_between_a)s
                   --b=%(findmarkers_between_b)s
                   --testuse=%(findmarkers_test)s
                   --threshuse=%(findmarkers_threshuse)s
                   --minpct=%(findmarkers_minpct)s
                   --mindiffpct=-Inf
                   --annotation=annotation.dir/ensembl.to.entrez.tsv.gz
                   %(conserved_options)s
                   --numcores=%(findmarkers_numcores)s
                   --outdir=%(outdir)s
                   &> %(cluster_log_file)s
                ''' % dict(PARAMS, **SPEC, **locals()))

    P.run(statements)
    IOTools.touch_file(outfile)


@active_if(PARAMS["findmarkers_between"])
@transform(findMarkersBetweenConditions,
           regex(r"(.*)/findMarkersBetweenConditions.sentinel"),
           r"\1/summariseMarkersBetweenConditions.sentinel")
def summariseMarkersBetweenConditions(infile, outfile):
    '''
    Make summary tables and plots of within-cluster DE genes.

    The per-cluster results files are aggregated. A heatmap of the top
    cluster markers is generated. A summary excel file is generated.
    Tables for geneset enrichment testing are prepared.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    testname = os.path.basename(outfile).split(".")[1]

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"])

    # make sumamary tables and plots of the differentially expressed genes
    statement = '''Rscript %(cellhub_code_dir)s/R/seurat_summariseMarkersBetween.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --testfactor=%(findmarkers_between_testfactor)s
                   --a=%(findmarkers_between_a)s
                   --b=%(findmarkers_between_b)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@active_if(PARAMS["findmarkers_between"])
@transform(summariseMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/summariseMarkersBetweenConditions.sentinel"),
           r"\1/condition.marker.de.plots.dir/characteriseClusterMarkersBetween.tex")
def characteriseClusterMarkersBetweenConditions(infile, outfile):
    '''
    Characterise within-cluster DE genes.

    Diagnostic summary plots of differentially expressed genes
    and violin plots are generated.

    Parallelised per-cluster.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.between." +
                                PARAMS["findmarkers_between_testfactor"] +
                                ".summary.table.tsv.gz")

    # not all clusters may have degenes
    degenes = pd.read_csv(marker_table, sep="\t")
    declusters = [x for x in set(degenes["cluster"].values)]

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    statements = []
    tex = []

    for i in declusters:

        if str(i) == "911":
            continue

        cluster_log_file = outfile[:-len(".tex")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(cellhub_code_dir)s/R/seurat_characteriseClusterDEGenes.R
                    --degenes=%(marker_table)s
                    --seuratobject=%(seurat_object)s
                    --seuratassay=RNA
                    --clusterids=%(cluster_ids)s
                    --cluster=%(i)s
                    --testfactor=%(findmarkers_between_testfactor)s
                    --a=%(findmarkers_between_a)s
                    --b=%(findmarkers_between_b)s
                    --useminfc=FALSE
                    --outdir=%(outdir)s
                    --plotdirvar=conditionMarkerDEPlotsDir
                    &> %(cluster_log_file)s
                    ''' % dict(PARAMS, **SPEC, **locals())

        cluster_tex_file = ".".join(["characterise.degenes", str(i),
                                     "between.tex"])

        tex.append("\\input{\\conditionMarkerDEPlotsDir/" + cluster_tex_file + "}")
        statements.append(statement)

    P.run(statements)

    with open(outfile, "w") as out_tex:
        for line in tex:
            out_tex.write(line + "\n")


@active_if(PARAMS["findmarkers_between"])
@transform(summariseMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/(.*).sentinel"),
           r"\1/condition.marker.de.plots.dir/plotMarkerNumbersBetween.sentinel")
def plotMarkerNumbersBetweenConditions(infile, outfile):
    '''
    Summarise the numbers of within-cluster DE genes.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.between." +
                                PARAMS["findmarkers_between_testfactor"] +
                                ".summary.table.tsv.gz")

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    statement = '''Rscript %(cellhub_code_dir)s/R/seurat_summariseMarkerNumbers.R
                   --degenes=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --testfactor=%(findmarkers_between_testfactor)s
                   --a=%(findmarkers_between_a)s
                   --b=%(findmarkers_between_b)s
                   --minfc=2
                   --minpadj=0.05
                   --outdir=%(outdir)s
                   --plotdirvar=conditionMarkerDEPlotsDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ########### marker gene (and within cluster DE) analysis ################## #
# ########################################################################### #

@follows(characteriseClusterMarkers,
         topMarkerHeatmap,
         plotMarkerNumbers,
         characteriseClusterMarkersBetweenConditions,
         plotMarkerNumbersBetweenConditions)
@files(None, "markers.sentinel")
def markers(infile, outfile):
    '''
       Collect the marker plots
    '''

    IOTools.touch_file(outfile)


# ########################################################################### #
# ######################### Geneset Analysis ################################ #
# ########################################################################### #

def parseGMTs(param_keys=["gmt_pathway_files_"]):
    '''Helper function for parsing the lists of GMT files'''

    all_files = []
    all_names = []

    for param_key in param_keys:


        gmts = [x for x in PARAMS.keys()
                if x.startswith(param_key)]

        if len(gmts) > 0:
            all_files += [PARAMS[x] for x in gmts]

            all_names += [x.replace(param_key, "")
                              for x in gmts]

    if len(all_files) == 0:
        all_files = "none"
        all_names = "none"
    else:
        all_files = ",".join(all_files)
        all_names = ",".join(all_names)

    return all_names, all_files


# ------------------- < between cluster geneset analysis > ------------------ #

@active_if(PARAMS["run_genesets"])
@follows(summariseMarkers)
@transform(findMarkers,
           regex(r"(.*)/cluster.markers.dir/.*.sentinel"),
      #     add_inputs(getGenesetAnnotations),
           r"\1/cluster.genesets.dir/geneset.analysis.sentinel")
def genesetAnalysis(infiles, outfile):
    '''
    Naive geneset over-enrichment analysis of cluster marker genes.

    Testing is performed with the gsfisher package.

    GO categories and KEGG pathways are tested by default.

    Arbitrary sets of genes cat be supplied as GMT files
    (e.g. such as those from MSigDB).
    '''

    findMarkersLog, genesetAnno = infiles

    spec, SPEC = TASK.get_vars(findMarkersLog, outfile, PARAMS)

    anno = os.path.join(os.path.dirname(genesetAnno),
                        "ensembl.to.entrez.tsv.gz")

    kegg_pathways = os.path.join(os.path.dirname(genesetAnno),
                                 "kegg_pathways.rds")

    param_keys = ["gmt_celltype_files_",
                  "gmt_pathway_files_"]
    gmt_names, gmt_files = parseGMTs(param_keys=param_keys)

    statements = []

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    for i in spec.clusters:

        if str(i) == "911":
            continue

        cluster_log_file = os.path.join(spec.outdir, "geneset.analysis." + str(i) + ".log")

        markers = os.path.join(spec.indir, "markers.summary.table.tsv.gz")

        universe = os.path.join(
            spec.indir, "markers.cluster." + str(i) + ".universe.tsv.gz")

        if not os.path.exists(universe):
            E.warn("Skipping geneset analysis: %s does not exist" % universe)
            continue

        statements.append('''Rscript %(cellhub_code_dir)s/R/genesetAnalysis.R
                            --markers=%(markers)s
                            --universe=%(universe)s
                            --species=%(annotation_species)s
                            --annotation=%(anno)s
                            --kegg_pathways=%(kegg_pathways)s
                            --gmt_names=%(gmt_names)s
                            --gmt_files=%(gmt_files)s
                            --cluster=%(i)s
                            --adjpthreshold=%(genesets_marker_adjpthreshold)s
                            --direction=positive
                            --outdir=%(outdir)s
                            &> %(cluster_log_file)s
                      ''' % dict(PARAMS, **SPEC, **locals()))

    P.run(statements)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_genesets"])
@transform(genesetAnalysis,
           regex(r"(.*)/.*.sentinel"),
           r"\1/summarise.geneset.analysis.sentinel")
def summariseGenesetAnalysis(infile, outfile):
    '''
    Summarise the geneset over-enrichment analyses of cluster marker genes.

    Enriched pathways are summarised in an Excel table and a heatmap.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    # need to sort out the dependencies properly!
    genesetdir = os.path.dirname(infile)

    param_keys = ["gmt_celltype_files_",
                  "gmt_pathway_files_"]
    gmt_names, gmt_files = parseGMTs(param_keys=param_keys)

    # Read clusters

    use_adjusted = str(PARAMS["genesets_use_adjusted_pvalues"]).upper()
    show_common = str(PARAMS["genesets_show_common"]).upper()

    show_detailed = str(PARAMS["genesets_show_detailed"])

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    statement = '''Rscript %(cellhub_code_dir)s/R/summariseGenesets.R
                         --genesetdir=%(genesetdir)s
                         --gmt_names=%(gmt_names)s
                         --show_detailed=%(show_detailed)s
                         --clusters=%(cluster_table)s
                         --mingenes=%(genesets_min_fg_genes)s
                         --pvaluethreshold=%(genesets_pvalue_threshold)s
                         --padjustmethod=%(genesets_padjust_method)s
                         --useadjusted=%(use_adjusted)s
                         --minoddsratio=%(genesets_min_odds_ratio)s
                         --showcommon=%(show_common)s
                         --outprefix=%(outdir)s/cluster.genesets
                         --prefix=genesets
                         --plotdirvar=clusterGenesetsDir
                         --pdf=%(plot_pdf)s
                    &> %(log_file)s
                      ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


# ------------------- < within cluster geneset analysis > ------------------- #

@active_if(PARAMS["run_genesets"])
@active_if(PARAMS["findmarkers_between"])
@follows(summariseMarkersBetweenConditions)
@transform(findMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/.*.sentinel"),
       #    add_inputs(getGenesetAnnotations),
           r"\1/condition.genesets.dir/geneset.analysis.between.conditions.sentinel")
def genesetAnalysisBetweenConditions(infiles, outfile):
    '''
    Naive geneset over-enrichment analysis of genes DE within-cluster.

    Testing is performed with the gsfisher package.

    GO categories and KEGG pathways are tested by default.

    Arbitrary sets of genes cat be supplied as GMT files
    (e.g. such as those from MSigDB).
    '''

    findMarkersLog, genesetAnno = infiles

    spec, SPEC = TASK.get_vars(findMarkersLog, outfile, PARAMS)

    anno = os.path.join(os.path.dirname(genesetAnno),
                        "ensembl.to.entrez.tsv.gz")

    kegg_pathways = os.path.join(os.path.dirname(genesetAnno),
                                 "kegg_pathways.rds")

    gmt_names, gmt_files = parseGMTs(param_keys=["gmt_pathway_files_"])

    statements = []

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    for i in spec.clusters:

        if str(i) == "911":
            continue

        cluster_log_file = os.path.join(
            spec.outdir, "geneset.analysis.between." + str(i) + ".log")

        markers = os.path.join(
            spec.indir, "markers.between." +
            PARAMS["findmarkers_between_testfactor"] +
            ".summary.table.tsv.gz")

        universe = os.path.join(
            spec.indir, "markers.between." +
            PARAMS["findmarkers_between_testfactor"] +
            ".cluster." + str(i) + ".universe.tsv.gz")

        if not os.path.exists(universe):
            E.warn("Skipping geneset analysis: %s does not exist" % universe)
            continue

        statements.append('''Rscript %(cellhub_code_dir)s/R/genesetAnalysis.R
                            --markers=%(markers)s
                            --universe=%(universe)s
                            --species=%(annotation_species)s
                            --annotation=%(anno)s
                            --kegg_pathways=%(kegg_pathways)s
                            --gmt_names=%(gmt_names)s
                            --gmt_files=%(gmt_files)s
                            --cluster=%(i)s
                            --adjpthreshold=%(genesets_marker_adjpthreshold)s
                            --direction=both
                            --prefix=genesets.between
                            --outdir=%(outdir)s
                            &> %(cluster_log_file)s
                      ''' % dict(PARAMS, **SPEC, **locals()))

    P.run(statements)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_genesets"])
@active_if(PARAMS["findmarkers_between"])
@transform(genesetAnalysisBetweenConditions,
           regex(r"(.*)/.*.sentinel"),
           r"\1/summarise.geneset.analysis.between.conditions.sentinel")
def summariseGenesetAnalysisBetweenConditions(infile, outfile):
    '''
    Summarise the geneset over-enrichment analyses of genes DE within-cluster.

    Enriched pathways are summarised in an Excel table and a heatmap.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    genesetdir = os.path.dirname(infile)

    gmt_names, gmt_files = parseGMTs(param_keys=["gmt_pathway_files_"])

    use_adjusted = str(PARAMS["genesets_use_adjusted_pvalues"]).upper()
    show_common = str(PARAMS["genesets_show_common"]).upper()
    show_detailed = str(PARAMS["genesets_show_detailed"])


    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    statement = '''Rscript %(cellhub_code_dir)s/R/summariseGenesets.R
                         --genesetdir=%(genesetdir)s
                         --gmt_names=%(gmt_names)s
                         --show_detailed=%(show_detailed)s
                         --clusters=%(cluster_table)s
                         --mingenes=%(genesets_min_fg_genes)s
                         --pvaluethreshold=%(genesets_pvalue_threshold)s
                         --padjustmethod=%(genesets_padjust_method)s
                         --minoddsratio=%(genesets_min_odds_ratio)s
                         --useadjusted=%(use_adjusted)s
                         --showcommon=%(show_common)s
                         --outprefix=%(outdir)s/condition.genesets
                         --prefix=genesets.between
                         --plotdirvar=conditionGenesetsDir
                         --pdf=%(plot_pdf)s
                    &> %(log_file)s
                      ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


# ---------------------- < geneset analysis target > ---------------------- #

@files([summariseGenesetAnalysis,
        summariseGenesetAnalysisBetweenConditions],
       "genesets.sentinel")
def genesets(infile, outfile):
    '''
       Intermediate target to run geneset tasks
    '''

    IOTools.touch_file(outfile)


# ########################################################################### #
# ##################### Target to collect plots ############################# #
# ########################################################################### #

@files([
         summariseSingleR,
         compareClusters,
         clustree,
         paga,
         plotRdimsFactors,
         plotRdimsClusters,
         plotRdimsGenes,
         plotRdimsMarkers,
         plotGroupNumbers,
         extraClusterMarkerPlots,
         knownMarkerViolins], "plots.sentinel")
def plots(infile, outfile):
    '''
    Intermediate target to collect plots.
    '''

    IOTools.touch_file(outfile)


# ########################################################################### #
# ################## PDF report generation (via Latex) ###################### #
# ########################################################################### #

# High quality pdf reports are generated which can be easily shared.
#
# The reports incorporate raster (png) graphics. PDF versions of each graphic
# are also avaliable in the individual run folders.

# @follows(taskSummary,
#          markers,
#          genesets,
#          plots,
#          summariseGenesetAnalysis)

# here we use add_inputs to force the pipeline to
# re-run the task if it is behind any of the upstream.

@transform(plotRdimsClusters,
           regex("(.*)/rdims.visualisation.dir/plot.rdims.cluster.sentinel"),
           add_inputs(taskSummary, markers, genesets, plots, summariseGenesetAnalysis),
           r"\1/latex.dir/report.vars.sty")
def latexVars(infiles, outfile):
    '''
    Prepare a file containing the latex variable definitions.
    '''

    infile = infiles[0]

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    outdir = spec.outdir



    clusterDir = spec.cluster_dir

    compDir = spec.component_dir

    outfile_name = os.path.basename(outfile)

    singleRDir = os.path.join(compDir,
                              "singleR.dir")

    clusterGenesetsDir = os.path.join(clusterDir,
                              "cluster.genesets.dir")
    clusterMarkerDEPlotsDir = os.path.join(clusterDir,
                              "cluster.marker.de.plots.dir")
    clusterMarkerRdimsPlotsDir = os.path.join(clusterDir,
                                             "cluster.marker.rdims" +\
                                             ".plots.dir")
    clusterMarkersDir = os.path.join(clusterDir,
                                     "cluster.markers.dir")
    conditionGenesetsDir = os.path.join(clusterDir,
                              "condition.genesets.dir")
    conditionMarkerDEPlotsDir = os.path.join(clusterDir,
                              "condition.marker.de.plots.dir")
    conditionMarkersDir = os.path.join(clusterDir,
                                     "condition.markers.dir")
    genelistsDir = os.path.join(clusterDir,
                                "genelists.dir")
    knownmarkersDir = os.path.join(clusterDir,
                                   "known.markers.dir")
    diffmapDir = os.path.join(clusterDir,
                              "dm.visualisation.dir")
    groupNumbersDir = os.path.join(clusterDir,
                                   "group.numbers.dir")
    umapDir = os.path.join(compDir,
                           "umap.dir")

    rdimsVisClusterDir = os.path.join(clusterDir,
                               "rdims.visualisation.dir")
    rdimsVisFactorDir = os.path.join(compDir,
                               "rdims.visualisation.dir")

    rdimsVisSingleRDir = os.path.join(compDir, "singleR.dir",
                               "rdims.visualisation.dir")

    # rdimsVisMethod = RDIMS_VIS_METHOD
    rdimsVisMethodShort = "umap"
    rdimsVisMethod = "umap.mindist_" + str(PARAMS["umap_mindist"])

    velocityDir = os.path.join(compDir,
                               "velocity.dir")
    pagaDir = os.path.join(clusterDir,
                               "paga.dir")
    phateDir = os.path.join(compDir,
                            "phate.dir")
    sampleDir = spec.sample_dir

    clusterDirBaseName = os.path.basename(clusterDir)

    nPCs = spec.components
    resolution = spec.resolution
    deTest = PARAMS["findmarkers_test"]
    algorithm = PARAMS["cluster_algorithm"]


    runName = nPCs + "\\_" + resolution #clusterDirBaseName.replace("_", "\\_")

    runDetails = ("no. components: " + str(nPCs) +
                  ", cluster resolution: " + str(resolution) +
                  ", cluster algorithm: " + str(algorithm) +
                  ", de test: " + deTest)

    reductionType = PARAMS["dimreduction_method"]

    sample = Path(outfile).parts[0].split(".")[0]

    jobName = runName  #sample + "_" + runName.replace(".cluster.dir", "")

    sample = sample.replace("_", "\\_")

    latentvars = PARAMS["regress_latentvars"].replace("_", "\\_")

    if PARAMS["findmarkers_conserved"]:
        conservedFactor = PARAMS["findmarkers_conserved_factor"]
        conservedFactor = conservedFactor.replace("_", "\\_")
    else:
        conservedFactor = "None"

    if PARAMS["findmarkers_conserved_between"]:
        conservedBetweenFactor = PARAMS["findmarkers_conserved_between_factor"]
        conservedBetweenFactor = conservedBetweenFactor.replace("_", "\\_")
    else:
        conservedBetweenFactor = "None"

    if PARAMS["normalization_method"] == "log-normalization":
        varGeneMethod = PARAMS["vargenes_method"]
    elif PARAMS["normalization_method"] == "sctransform":
        varGeneMethod = "SCTransform"
    else:
        raise ValueError("unrecognised normalization method")

    vars = {"sample": "%(sample)s" % locals(),
            "projectName": "%(projectname)s" % PARAMS,
            "reportAuthor": "%(author)s" % PARAMS,
#            "runDir": "%(runDir)s" % locals(),
            "compDir": "%(compDir)s" % locals(),
            "sampleDir": "%(sampleDir)s" % locals(),
            "clusterDir": "%(clusterDir)s" % locals(),
            "singleRDir": "%(singleRDir)s" % locals(),
#            "tsneDir": "%(tsneDir)s" % locals(),
            "clusterGenesetsDir": "%(clusterGenesetsDir)s" % locals(),
            "clusterMarkerDEPlotsDir": "%(clusterMarkerDEPlotsDir)s" % locals(),
            "clusterMarkerRdimsPlotsDir": "%(clusterMarkerRdimsPlotsDir)s" % locals(),
            "clusterMarkersDir": "%(clusterMarkersDir)s" % locals(),
            "conditionGenesetsDir": "%(conditionGenesetsDir)s" % locals(),
            "conditionMarkerDEPlotsDir": "%(conditionMarkerDEPlotsDir)s" % locals(),
            "conditionMarkersDir": "%(conditionMarkersDir)s" % locals(),
            "knownmarkersDir": "%(knownmarkersDir)s" % locals(),
            "genelistsDir": "%(genelistsDir)s" % locals(),
            "diffmapDir": "%(diffmapDir)s" % locals(),
            "groupNumbersDir": "%(groupNumbersDir)s" % locals(),
            "umapDir": "%(umapDir)s" % locals(),
            "rdimsVisClusterDir": "%(rdimsVisClusterDir)s" % locals(),
            "rdimsVisFactorDir": "%(rdimsVisFactorDir)s" % locals(),
            "rdimsVisSingleRDir": "%(rdimsVisSingleRDir)s" % locals(),
            "rdimsVisMethod": "%(rdimsVisMethod)s" % locals() ,
            "rdimsVisMethodShort": "%(rdimsVisMethodShort)s" % locals() ,
            "velocityDir": "%(velocityDir)s" % locals(),
            "pagaDir": "%(pagaDir)s" % locals(),
            "phateDir": "%(phateDir)s" % locals(),
            "runName": "%(runName)s" % locals(),
            "runDetails": "%(runDetails)s" % locals(),
            "tenxDir": "%(cellhub_code_dir)s" % PARAMS,
            "nPCs": "%(nPCs)s" % locals(),
            "normalizationMethod": "%(normalization_method)s" % PARAMS,
            "reductionType": "%(reductionType)s" % locals(),
#            "tSNEPerplexity": "%(tsne_perplexity)s" % PARAMS,
#            "tSNEMaxIter": "%(tsne_maxiter)s" % PARAMS,
#            "tSNEFast": "%(tsne_fast)s" % PARAMS,
            "nPositiveMarkers": "%(exprsreport_n_positive)s" % PARAMS,
            "nNegativeMarkers": "%(exprsreport_n_negative)s" % PARAMS,
            "nnK": "%(neighbors_n_neighbors)s" % PARAMS,
            "nnMethod": "%(neighbors_method)s" % PARAMS,
            "nnMetric": "%(neighbors_metric)s" % PARAMS,
            "resolution": "%(resolution)s" % locals(),
            "clusteringAlgorithm": "%(algorithm)s" % locals(),
            "deTest": "%(deTest)s" % locals(),
            "threshUse": "%(findmarkers_threshuse)s" % PARAMS,
            "minPct": "%(findmarkers_minpct)s" % PARAMS,
            "qcMinGenes": "%(qc_mingenes)s" % PARAMS,
            "qcMaxMito": "%(qc_maxpercentmito)s" % PARAMS,
            "minCells": "%(qc_mincells)s" % PARAMS,
            "modelType": "%(regress_modeluse)s" % PARAMS,
            "latentVariables": "%(latentvars)s" % locals(),
            "cellCycle": "%(regress_cellcycle)s" % PARAMS,
            "varGeneMethod": "%(varGeneMethod)s" % locals(),
            "sdCutOff": "%(vargenes_sdcutoff)s" % PARAMS,
            "conservedFactor": "%(conservedFactor)s" % locals(),
            "conservedBetweenFactor": "%(conservedBetweenFactor)s" % locals()}

    with open(outfile, "w") as ofh:
        for command, value in vars.items():

            ofh.write("\\newcommand{\\" + command + "}{" + value + "}\n")


@active_if(PARAMS["run_exprsreport"])
@transform(latexVars,
           regex("(.*)/report.vars.sty"),
           r"\1/geneExpressionReport.pdf")
def geneExpressionReport(infile, outfile):
    '''
     Prepare a PDF report of the expression of genes interest.

     The expression of  manually specified sets of genes and of
     discovered cluster markers is visualised.
    '''

    outfile_name = os.path.basename(outfile)
    jobName = outfile_name[:-len(".pdf")]

    outdir = os.path.dirname(outfile)
    compilation_dir = os.path.join(outdir, ".latex_compilation.dir")

    latexVars = os.path.join(outdir, "report.vars")

    try:
        os.stat(compilation_dir)
    except FileNotFoundError:
        os.mkdir(compilation_dir)

    statement = '''pdflatex -output-directory=%(compilation_dir)s
                            -jobname=%(jobName)s
                            %(draft_mode)s
      '\\def\\latexVars{%(latexVars)s}
       \\def\\reportTitle{pipeline\\_seurat.py: gene expression report}
       \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/geneExpressionReport.tex
       \\input %(cellhub_code_dir)s/latex/endmatter.tex'
       '''

    # Deliberately run twice - necessary for LaTeX compilation..
    draft_mode="-draftmode"
    P.run(statement)
    draft_mode=""
    P.run(statement)

    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, outfile_name),
                outfile)


@follows(summariseMarkers,
         extraClusterMarkerPlots,
         characteriseClusterMarkers)
@active_if(PARAMS["run_marker_report"])
@transform(latexVars,
           regex("(.*)/report.vars.sty"),
           r"\1/clusterMarkerReport.pdf")
def markerReport(infile, outfile):
    '''
     Prepare a PDF report visualising the discovered cluster markers
    '''

    spec, SPEC = TASK.get_vars(infile, infile, PARAMS)

    marker_table = os.path.join(spec.cluster_dir,
                                "cluster.markers.dir",
                                "markers.summary.table.tsv.gz")

    # not all clusters may have degenes
    markers = pd.read_csv(marker_table, sep="\t")
    clusters_with_markers = [x for x in markers.cluster.unique()]

    tex_file = os.path.join(spec.outdir,
                            "cluster.marker.report.tex")

    with open(tex_file,"w") as tex:

        def _add_figure(plot_file=None,
                        caption=None,
                        tex=tex,
                        width="1",
                        height="0.9"):

            heatmap_fig = {"width": "1", "height": "0.9",
                           "path": plot_file,
                           "caption": caption
            }

            tex.write(textwrap.dedent(
                templates.figure % heatmap_fig))
            tex.write("\n")

        tex.write(templates.subsection % {"title": "overview plots"})
        tex.write("\n")

        _add_figure(os.path.join(spec.cluster_dir, "rdims.visualisation.dir",
                                 "umap.mindist_" + str(PARAMS["umap_mindist"]) +\
                                 ".cluster_id"),
                    width = "1", height= ".9",
                    caption = "UMAP coloured by cluster  (resolution " + spec.resolution + ")")


        tmh = os.path.join(spec.cluster_dir, "cluster.markers.dir",
                           "markers.summary.heatmap")

        if(os.path.exists(tmh)):
            _add_figure(tmh,
                        width = "1", height= "0.9",
                        caption = "Marker summary heatmap (resolution " + spec.resolution + ")")


        for clust in clusters_with_markers:

            if str(clust) == "911":
                continue

            tex.write(templates.subsection % {"title": "Markers for cluster: " + str(clust)})
            tex.write("\n")

            fig = "heatmap"
            _add_figure(os.path.join(spec.cluster_dir, "cluster.marker.extra.plots.dir",
                                     "cluster." + str(clust) + "." + fig),
                        width = "1", height= "0.25",
                        caption = "cluster " + str(clust) + " " + fig)

            fig = "dotplot"
            _add_figure(os.path.join(spec.cluster_dir, "cluster.marker.extra.plots.dir",
                                     "cluster." + str(clust) + "." + fig),
                        width = "1", height= "0.3",
                        caption = "cluster " + str(clust) + " " +fig)

            fig = "rdims"
            _add_figure(os.path.join(spec.cluster_dir, "cluster.marker.extra.plots.dir",
                                     "cluster." + str(clust) + "." + fig),
                        width = "1", height= "0.5",
                        caption = "cluster " + str(clust) + " expression dot plot")

            # add the scatter plots.
            _add_figure(os.path.join(spec.cluster_dir,
                                     "cluster.marker.de.plots.dir",
                                     "dePlots." + str(clust)),
                        width = "1", height= "0.9",
                        caption = "cluster " + str(clust) + " differential expression plots")

            # Add the violin plots

            fig = "violins"
            _add_figure(os.path.join(spec.cluster_dir, "cluster.marker.extra.plots.dir",
                                     "cluster." + str(clust) + "." + fig),
                        width = "1", height= "0.7",
                        caption = "cluster " + str(clust) + " " + fig)




    outfile_name = os.path.basename(outfile)
    jobName = outfile_name[:-len(".pdf")]

    compilation_dir = os.path.join(spec.outdir, ".latex_compilation.dir")

    latexVars = os.path.join(spec.outdir, "report.vars")

    try:
        os.stat(compilation_dir)
    except FileNotFoundError:
        os.mkdir(compilation_dir)

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])


    statement = '''pdflatex -output-directory=%(compilation_dir)s
                            -jobname=%(jobName)s
                            %(draft_mode)s
      '\\def\\latexVars{%(latexVars)s}
       \\def\\reportTitle{pipeline\\_seurat.py: cluster marker report}
       \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/clusterMarkerReport.tex
       \\input %(tex_file)s
       \\input %(cellhub_code_dir)s/latex/endmatter.tex'
       '''

    print(statement)

    # Deliberately run twice - necessary for LaTeX compilation..
    draft_mode = "-draftmode"
    P.run(statement % dict(PARAMS, **SPEC, **locals()))

    draft_mode = ""
    P.run(statement % dict(PARAMS, **SPEC, **locals()))

    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, outfile_name),outfile)


@transform(latexVars,
           regex("(.*)/report.vars.sty"),
           r"\1/summaryReport.pdf")
def summaryReport(infile, outfile):
    '''
    Prepare a PDF summary report.
    '''

    outfile_name = os.path.basename(outfile)
    jobName = outfile_name[:-len(".pdf")]

    outdir = os.path.dirname(outfile)
    rundir = Path(outdir).parents[0]

    compilation_dir = os.path.join(outdir, ".latex_compilation.dir")

    latexVars = os.path.join(outdir, "report.vars.sty")

    try:
        shutil.rmtree(compilation_dir)
    except FileNotFoundError:
        pass

    os.mkdir(compilation_dir)

    # get the latex variables
    statement = '''pdflatex -output-directory=%(compilation_dir)s
                            -jobname=%(jobName)s
                            %(draft_mode)s
      '\\input %(latexVars)s
       \\def\\reportTitle{pipeline\\_seurat.py: summary report}
                '''
    # get the intro
    statement += '''
      \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/introReport.tex
      '''

    # begin the report (qc, hvg, pca dimension reduction)
    if(os.path.exists("data.dir")):
        statement += '''
          \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/beginReport.tex
          '''
        if PARAMS["run_explore_hvg_and_cell_cycle"]:
            statement += '''
            \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/hvgAndCellCycle.tex
            '''

        if PARAMS["normalization_method"] != "sctransform" and +\
           PARAMS["run_jackstraw"] == True:
            statement += '''
            \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/jackstrawSection.tex
            '''



    # add the section to visualise clusters and factors in reduced dimensions
    # (plots made by tsne or umap)
    statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/rdimsVisSection.tex
        '''

    # singleR section
    if(PARAMS["run_singleR"]):
        statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/singleRSection.tex
        '''

    # add the section with plots of cell and gene numbers etc.
    statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/numbersSection.tex
        '''

    if(PARAMS["run_compare_clusters"]):
       statement += '''
       \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/clusteringSection.tex
       '''

    nresolutions = len(str(PARAMS["runspecs_cluster_resolutions"]).split(","))

    if(nresolutions > 1):
       statement += '''
       \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/clustree.tex
       '''


    if(PARAMS["run_diffusionmap"]):
        statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/diffusionSection.tex
        '''

    if(PARAMS["run_phate"]):
        statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/phateSection.tex
        '''

    if(PARAMS["run_paga"]):
        statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/pagaSection.tex
        '''

    if(PARAMS["run_velocity"]):
        statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/scveloSection.tex
        '''

    if(PARAMS["run_velocity"] and PARAMS["run_paga"]):
        statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/scveloForceDirectedGraphSection.tex
        '''

    if(PARAMS["run_velocity"] and PARAMS["run_phate"]):
        statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/scveloPhateSection.tex
        '''

    if(PARAMS["run_knownmarkers"]):
        statement += '''
         \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/knownmarkersSection.tex
        '''

    statement += '''
      \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/markerGenes.tex
      '''

    if(PARAMS["run_top_marker_heatmap"]):
        statement += '''
        \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/topMarkerHeatmap.tex
        '''

    if(PARAMS["run_characterise_markers"]): # and not ...
        statement += '''
        \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/markerGenesByCluster.tex
        '''

    if(PARAMS["run_genesets"]):
        statement += '''
        \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/genesetSection.tex
                     '''

    # When relevant, add section that compares
    # two conditions within each cluster
    if os.path.exists(
            os.path.join(rundir, "condition.markers.dir", "findMarkersBetweenConditions.sentinel")):

        wcc_section_name = "withinClusterComparisonSection.tex"
        statement += '''
          \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/%(wcc_section_name)s
          '''

        if(PARAMS["run_genesets"]):
            statement += '''
        \\input %(cellhub_code_dir)s/pipelines/pipeline_scxl/genesetBetweenSection.tex
                         '''


    statement += '''\\input %(cellhub_code_dir)s/latex/endmatter.tex'
    '''

    # Deliberately run twice - necessary for LaTeX compilation..
    draft_mode = "-draftmode"
    P.run(statement)

    draft_mode = ""
    P.run(statement)

    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, outfile_name),
                outfile)


@follows(mkdir("reports.dir"), geneExpressionReport, markerReport)
@transform(summaryReport,
           regex(r"(.*).seurat.dir/components.(.*).dir/cluster.(.*).dir/latex.dir/summaryReport.pdf"),
           r"reports.dir/\1.\2_\3/export.sentinel")
def export(infile, outfile):
    '''
    Link output files to a directory in the "reports.dir" folder.

    Prepare folders containing the reports, differentially expressed genes
    and geneset tables for each analysis.
    '''


    spec, SPEC = TASK.get_vars(infile, infile, PARAMS)

    sample = Path(infile).parts[0].split(".")[0]

    cluster_run = spec.components + "_" + spec.resolution

    out_dir = os.path.join("reports.dir",
                           ".".join([sample, cluster_run]))

    run_dir = Path(os.path.dirname(infile)).parents[0]

    try:
        shutil.rmtree(out_dir)
    except FileNotFoundError:
        pass

    os.mkdir(out_dir)

    between_xlsx = "markers.between." + \
                   str(PARAMS["findmarkers_between_testfactor"]) + \
                   ".summary.table.xlsx"

    targets = [os.path.join(run_dir,"latex.dir","geneExpressionReport.pdf"),
               os.path.join(run_dir,"latex.dir","summaryReport.pdf"),
               os.path.join(run_dir,"latex.dir","clusterMarkerReport.pdf"),
               os.path.join(run_dir,"cluster.markers.dir","markers.summary.table.xlsx"),
               os.path.join(run_dir,"condition.markers.dir",between_xlsx),
               os.path.join(run_dir, "cluster.genesets.dir","cluster.genesets.xlsx"),
               os.path.join(run_dir, "condition.genesets.dir","condition.genesets.xlsx")]

    for target_file in targets:


        if os.path.exists(target_file):

            target = os.path.basename(target_file)

            link_name = os.path.join(out_dir, target)

            os.symlink(os.path.relpath(target_file, start=out_dir),
                       link_name)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ##################'## Generate cellxgene output ########################### #
# ########################################################################### #

@active_if(PARAMS["run_cellbrowser"])
@follows(mkdir("cellbrowser.dir"), summaryReport)
@transform("*.seurat.dir",
           regex(r"(.*).seurat.dir"),
           r"cellbrowser.dir/\1/cellbrowser.sentinel")
def cellbrowser(infile, outfile):
    '''
    Prepare cellbrowser instance for exploratory analysis or to share with
    collaborators. A cellbrowser instance is only generated for a defined
    runspecs configuration and only once per sample.'''

    # read in yml entries
    samples_specs = [s for s in PARAMS.keys()
                     if s.startswith("cellbrowser_")]
    samples_specs = [s for s in samples_specs if not "run" in s]

    # only run if sample ID from job is listed in yml
    sample_name = infile[:-len(".seurat.dir")]

    log_file = outfile.replace(".sentinel", ".log")

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    # make cellbrowser if sample is mentioned in yml file
    if "cellbrowser_"+sample_name in samples_specs:
        settings_use = PARAMS[str("".join([k for k in samples_specs
                                           if str(sample_name) in k]))]
        outdir_settings = os.path.join(outdir, str(settings_use))
        # set up required subfolders
        if not os.path.exists(outdir_settings):
            os.makedirs(outdir_settings)
        # cellbrowser input files written into following folder
        outdir_folder = os.path.join(outdir_settings, "infiles")
        if not os.path.exists(outdir_folder):
            os.makedirs(outdir_folder)

        seurat_path = sample_name + ".seurat.dir"

        # Rscript to generate input files

        # set the job threads and memory
        locals().update(
            TASK.get_resources(memory=PARAMS["resources_memory_standard"]))


        statement = '''Rscript %(cellhub_code_dir)s/R/cellbrowser_prep.R
                         --outdir=%(outdir_folder)s
                         --seurat_path=%(seurat_path)s
                         --runspecs=%(settings_use)s
                       &> %(log_file)s
                      '''
        P.run(statement)

        # python code to make configuration file
        out = open(os.path.join(outdir_settings, "cellbrowser.conf"), "w")
        conf = ""
        # cannot use projectname from pipeline.yml here as only letters/digits
        # allowed in name
        conf += 'name = "seuratPipeline"\n'
        conf += '''coords = [{"file":"infiles/UMAP.tsv","shortLabel":"UMAP"},
                             {"file":"infiles/FA.tsv","shortLabel":
                              "PAGA initiated force-directed graph"}]\n'''
        conf += 'shortLabel = "%s"\n' %PARAMS["projectname"]
        conf += 'exprMatrix = "infiles/exprMatrix.tsv.gz"\n'
        conf += 'meta = "infiles/meta.tsv"\n'
        conf += 'enumFields = ["cluster"]\n'
        conf += 'clusterField = "cluster"\n'
        conf += 'labelField = "cluster"\n'
        conf += 'colors = "infiles/colors.tsv"\n'
        conf += '''markers = [{"file": "infiles/markers.tsv",
                              "shortLabel": "Cluster markers identified by Seurat"}]\n'''
        out.write(conf)
        out.close()


        # python code to run cellbrowser
        cellbrowser_log = os.path.join(outdir_settings,
                                       "build_cb.log")
        cellbrowser_conf = os.path.join(outdir_settings, "cellbrowser.conf")
        outdir_cellbrowser = os.path.join(outdir_settings, "outfiles")
        statement = '''cbBuild -i %(cellbrowser_conf)s
                                -o %(outdir_cellbrowser)s
                                &> %(cellbrowser_log)s '''
        P.run(statement)

    else:
        # no cellbrowser for this sample
        statement = ''' echo "Do not generate cellbrowser"
                        > %(log_file)s '''
        P.run(statement)


    # add README to output folder
    readme_file = "cellbrowser.dir/README"
    if not os.path.exists(readme_file):
        statement = ''' echo "# to run cellbrowser, go to the chosen sample "
                        >> %(readme_file)s ;
                        echo "# folder (e.g. wildtype/30_0.8_1_wilcox) and use the "
                        >> %(readme_file)s ;
                        echo "# following command to open it on a port of your choice: "
                        >> %(readme_file)s ;
                        echo "cbBuild -i cellbrowser.init -o outfiles/ -p 8888"
                        >> %(readme_file)s  '''
        P.run(statement)

    IOTools.touch_file(outfile)


# --------------------------- < report target > ----------------------------- #

# This is the target normally used to execute the pipeline.

@follows(export, cellbrowser)
def report():
    pass


# ########################################################################### #
# ######################### Auxillary functions ############################# #
# ########################################################################### #

@transform(scanpyCluster,
           regex(r"(.*)/cluster.sentinel"),
           r"\1/cluster_counts.rds")
def aggregateUMIsPseudobulks(infile, outfile):
    '''
    Aggregate UMI counts across cells within cluster to form pseudobulks.

    Useful for performing e.g. DESeq2 analysis of clusters from
    multiple samples.
    '''

    outdir = os.path.dirname(infile)
    cluster_ids = os.path.join(outdir, "cluster_ids.rds")

    seurat_dir = Path(outfile).parents[1]
    sample_data_dir = str(seurat_dir).replace(".seurat", "")
    run_dir = Path(seurat_dir).parents[0]

    tenxdir = os.path.join(run_dir, 'data.dir', sample_data_dir)

    log_file = os.path.join(outdir, 'aggregated_clusters.log')

    locals().update(
        TASK.get_resources(memory=PARAMS["resources_memory_low"]))

    statement = '''Rscript %(cellhub_code_dir)s/R/aggregate_umis_pseudobulks.R
                           --tenxdir=%(tenxdir)s
                           --clusterids=%(cluster_ids)s
                           --outfile=%(outfile)s
                           &> %(log_file)s
                        '''

    P.run(statement)


# ------------------------ < auxillary target > ----------------------------- #

@follows(aggregateUMIsPseudobulks)
def aux():
    pass

# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #


@follows()
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
