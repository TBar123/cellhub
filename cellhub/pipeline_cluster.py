"""=============
Pipeline cluster
================

Overview
========

This pipeline performs clustering of integrated single cell datasets. Starting from an anndata
object with integrated coordinates (e.g. from Harmony or scVI) the pipeline:

* Computes the neighbour graph using the HNSW alogrithm
* Performs UMAP compuation and Leiden clustering (with ScanPy)
* Visualises QC statistics on the UMAPs and by cluster
* Visualises singleR results
* Finds cluster marker genes (using the ScanPy 'rank_genes_groups' function)
* Performs pathway analysis of the cluster phenotypes (with gsfisher)
* Prepares marker gene and summary reports
* Export an anndata for viewing with cellxgene

For plotting of data in R, the pipeline saves the input anndata in loom format and
reads data in R with the loomR library.


Usage
=====

See :doc:`Installation</Installation>` and :doc:`Usage</Usage>` on general
information how to use CGAT pipelines.

Configuration
-------------

It is recommended to perform the clustering in a new directory.

The pipeline requires a configured :file:`pipeline_cluster.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_cluster.py config

Inputs
------

The pipeline starts from an anndata object with the following structure.

* annadata.var.index -> ensembl_ids (use of gene names is not supported)
* anndata.X -> scaled data (a dense matrix)
* anndata.layers["counts"] -> raw counts (a sparse matrix)
* anndata.layers["log1p"] -> total count normalised, 1og1p transformed data (a sparse matrix)
* anndata.obs -> metadata (typically passed through from original cellhub object)
* anndata.obsm["X_rdim_name"] -> containing the integrated coordinates (where "rdim_name" matches
                                  the "runspec_rdim_name" parameter). TODO: rename this parameter.

It is strongly recommended to retain the information for all of the genes in all of the matrices 
(i.e. do not subset to HVGs!). This is important for marker gene discovery and pathway analysis.


Pipeline output
===============

The pipeline produces the following outputs:

1. Summary report

- Containing the overview UMAP plots, visualisation of QC and SingleR information 
- The result of the per-cluster pathway analysis

2. Marker report

- Containing heatmaps, violin plots, expression dotplots, MA and volcano plots for 
each cluster.

3. xlsx spreadsheets for the marker gene and pathway results

4. Anndata objects ready to be viewed with cellxgene


"""

#region Imports and Configuration

import os
import sys
import gzip
import glob
import shutil

from pathlib import Path
import pandas as pd

import yaml
import textwrap
from ruffus import *
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

import cellhub.tasks.control as C
import cellhub.tasks.fetch_cells as fetch_cells
import cellhub.tasks.TASK as TASK
import cellhub.tasks.templates as templates

# Override function to collect config files
P.control.write_config_files = C.write_config_files


# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline_cluster.yml" % os.path.splitext(__file__)[0],
     "../pipeline_cluster.yml",
     "pipeline_cluster.yml"])

# set the location of the code directory
PARAMS["cellhub_code_dir"] = Path(__file__).parents[1]

# automatically set paths on the cellhub api
cellhub_ensembl_annotations = os.path.join(PARAMS["source_cellhub"],
            "api/annotation/ensembl/ensembl.to.entrez.tsv.gz")

if not os.path.exists(cellhub_ensembl_annotations):
    raise ValueError("cellhub ensembl annotations file not found: " +
                     cellhub_ensembl_annotations)
    
PARAMS["cellhub_ensembl_annotations"] = cellhub_ensembl_annotations

cellhub_ensembl_map = os.path.join(PARAMS["source_cellhub"],
            "api/annotation/ensembl/ensembl.gene_name.map.tsv.gz")

if not os.path.exists(cellhub_ensembl_map):
    raise ValueError("cellhub ensembl map file not found: " +
                     cellhub_ensembl_map)
    
PARAMS["cellhub_ensembl_map"] = cellhub_ensembl_map

cellhub_kegg_pathways = os.path.join(PARAMS["source_cellhub"],
                                  "api/annotation/kegg/kegg.pathways.rds")

if not os.path.exists(cellhub_kegg_pathways):
    raise ValueError("cellhub kegg pathways file not found")
PARAMS["cellhub_kegg_pathways"] = cellhub_kegg_pathways

# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))

# ------------------------------ < functions > ------------------------------ #

#endregion

#region Setup

@files(None, "task.summary.table.tex")
def taskSummary(infile, outfile):
    '''Make a summary of optional tasks that will be run'''

    tasks, run = [], []

    for k,v in PARAMS.items():
        if k.startswith("run_"):
            tasks.append(k[4:])
            run.append(str(v))

    tab = pd.DataFrame(list(zip(tasks,run)),columns=["task","run"])
    print(tab)

    tab.to_latex(buf=outfile, index=False)


@files(PARAMS["source_anndata"],
       "preflight.sentinel")
def preflight(infile, outfile):
    '''
       Preflight sanity checks.
    '''

    log_file = outfile.replace(".sentinel", ".log")

    if PARAMS["markers_conserved"]:
        conserved = "--conserved"
    else:
        conserved = ""
        
    max_rdims = max(int(x.strip()) for x in 
                    str(PARAMS["runspecs_n_components"]).strip().split(","))

    statement = '''python %(cellhub_code_dir)s/python/cluster_preflight.py
                   --anndata=%(infile)s
                   --reduced_dims_name=%(source_rdim_name)s
                   --max_reduced_dims=%(max_rdims)s
                   %(conserved)s
                   --conserved_factor=%(markers_conserved_factor)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

@follows(preflight)
@files(PARAMS["source_anndata"],
       "metadata.dir/metadata.sentinel")
def metadata(infile, outfile):
    '''
       Export the metadata (obs) from the source anndata
       for use in the plotting tasks
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"], PARAMS=PARAMS)

    outfile_name = outfile.replace(".sentinel", ".tsv.gz")

    statement = '''python %(cellhub_code_dir)s/python/cluster_metadata.py
                   --source_anndata=%(infile)s
                   --outfile=%(outfile_name)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

@follows(preflight)
@files(PARAMS["source_anndata"],
       "loom.dir/data.loom")
def loom(infile, outfile):
    '''
       Export the data to the loom file format. This is used
       as an exchange format for plotting in R. 
    '''

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''python %(cellhub_code_dir)s/python/cluster_export_loom.py
                   --anndata=%(infile)s
                   --loom=%(outfile)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

#endregion

#region Neighbor graph

# ########################################################################### #
# ###################### Compute the neighbor graph ######################### #
# ########################################################################### #


def genNeighbourGraphs():

    components_str = str(PARAMS["runspecs_n_components"])
    components = components_str.strip().replace(" ", "").split(",")

    outname = "neighbour.graph.sentinel"

    infile = PARAMS["source_anndata"]

    for comps in components:

        outdir = "out." + comps + ".comp.dir"

        outfile = os.path.join(outdir, outname)
        yield [infile, outfile]

@follows(preflight)
@files(genNeighbourGraphs)
def neighbourGraph(infile, outfile):
    '''
       Compute the neighbor graph.
       A miniminal anndata is saved for UMAP computation and clustering.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    print(SPEC)

    reductiontype = PARAMS["dimreduction_method"]

    #SPEC["components"] = outfile.split("/")[1][len("components."):-len(".dir")]

    ncomps = spec.components

    # set the job threads and memory
    if PARAMS["neighbors_full_speed"]:
        full_speed = "--fullspeed"
    else:
        full_speed = ""

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"], PARAMS=PARAMS)

    outfile_name = outfile.replace(".sentinel", ".h5ad")

    statement = '''python %(cellhub_code_dir)s/python/cluster_neighbor_graph.py
                   --source_anndata=%(infile)s
                   --reduced_dims_name=%(source_rdim_name)s
                   --outfile=%(outfile_name)s
                   --ncomps=%(ncomps)s
                   --method=%(neighbors_method)s
                   --threads=%(neighbors_threads)s
                   --k=%(neighbors_n_neighbors)s
                   --metric=%(neighbors_metric)s
                   %(full_speed)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

#endregion

#region Cluster

# ########################################################################### #
# ############################ Clustering ################################### #
# ########################################################################### #

def genScanpyClusterJobs():

    components_str = str(PARAMS["runspecs_n_components"])
    components = components_str.strip().replace(" ", "").split(",")

    if PARAMS["runspecs_cluster_resolutions"]:
        resolutions = [ x.strip() for x in
                        str(PARAMS["runspecs_cluster_resolutions"]).split(",") ]

    outname = "scanpy.clusters.sentinel"

    for comps in components:

        outdir = "out." + comps + ".comp.dir"
        infile = os.path.join(outdir,
        "neighbour.graph.h5ad")

        if PARAMS["runspecs_predefined_clusters"] :

            subdir = "cluster.predefined.dir"
            outfile = os.path.join(outdir, subdir, outname)
            yield [infile, outfile]

        if PARAMS["runspecs_cluster_resolutions"]:
            for resolution in resolutions:

                subdir = "cluster." + resolution + ".dir"
                outfile = os.path.join(outdir, subdir, outname)
                yield [infile, outfile]


@follows(neighbourGraph)
@files(genScanpyClusterJobs)
def scanpyCluster(infile, outfile):
    '''
       Discover clusters using ScanPy.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"])

    if not "cluster.predefined.dir" in spec.outdir:

        statement = '''python %(cellhub_code_dir)s/python/cluster_cluster.py
                   --anndata=%(infile)s
                   --algorithm=%(cluster_algorithm)s
                   --resolution=%(resolution)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

        P.run(statement)

    IOTools.touch_file(outfile)


@transform(scanpyCluster,
           regex(r"(.*)/scanpy.clusters.sentinel"),
           r"\1/cluster.sentinel")
def cluster(infile, outfile):
    '''
    Post-process the clustering result.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    scanpy_cluster_tsv = infile.replace(".sentinel",".tsv.gz")

    if "cluster.predefined.dir"  in spec.indir:
        predefined='--predefined=' + PARAMS["runspecs_predefined_clusters"]
    else:
        predefined=""

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_post_process.R
                   --clusters=%(scanpy_cluster_tsv)s
                   %(predefined)s
                   --mincells=10
                   --outdir=%(outdir)s
                   > %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_compare_clusters"])
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/compare.clusters.sentinel")
def compareClusters(infile, outfile):
    '''
       Draw a dendrogram showing the relationship between the clusters.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    reductiontype = PARAMS["source_rdim_name"]

    if spec.resolution == "predefined":

        # TODO: Fix.
        cluster_file = sample + ".cluster_ids.rds"

        if os.path.exists(cluster_file):
            predefined = "--predefined=%(cluster_file)s" % locals()

        else:
            raise ValueError("Predefined cluster assignment file (%(cluster_file)s) not found" % locals())

    else:
        predefined = ""

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    statement = '''python %(cellhub_code_dir)s/python/cluster_compare.py
                   --source_anndata=%(source_anndata)s
                   --clusterids=%(cluster_ids)s
                   --ncomp=%(components)s
                   --outdir=%(outdir)s
                   --reduced_dims_name=%(reductiontype)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ############### compare the clusters across resolutions ################### #
# ########################################################################### #

nresolutions = len(str(PARAMS["runspecs_cluster_resolutions"]).split(","))

@active_if(nresolutions > 1)

@follows(cluster)
@transform(neighbourGraph,
           regex(r"(.*)/neighbour.graph.sentinel"),
           r"\1/clustree.sentinel")
def clustree(infile, outfile):
    '''
       Run clustree.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    id_files = [ os.path.join(spec.outdir,
                              "cluster." + r + ".dir",
                              "cluster_ids.tsv.gz")
                 for r in spec.resolutions ]

    res_str = ",".join(spec.resolutions)
    id_files_str = ",".join(id_files)

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"])

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_clustree.R
                   --resolutions=%(res_str)s
                   --clusteridfiles=%(id_files_str)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

@active_if(PARAMS["run_paga"])
@follows(neighbourGraph)
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/paga.dir/paga.sentinel")
def paga(infile, outfile):
    '''
       Run partition-based graph abstraction (PAGA)
       see: https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1663-x
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_high"])

    statement = '''python %(cellhub_code_dir)s/python/cluster_paga.py
                   --anndata=%(neighbour_graph_anndata)s
                   --outdir=%(outdir)s
                   --cluster_ids=%(cluster_ids)s
                   --cluster_colors=%(cluster_colors)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

# endregion

#region UMAP

# ########################################################################### #
# ############### UMAP analysis and related plots ########################### #
# ########################################################################### #

@transform(neighbourGraph,
           regex(r"(.*)/neighbour.graph.sentinel"),
           r"\1/umap.dir/umap.sentinel")
def UMAP(infile, outfile):
    '''
       Compute the UMAP layout.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_high"],
        cpu=2)

    mindists = [x.strip() for x in PARAMS["umap_mindists"].split(",")]

    statements = []
    for mindist in mindists:

        mindist_log_file = outfile.replace(".sentinel",
                                           "." + mindist + ".log")

        statement = '''python %(cellhub_code_dir)s/python/cluster_umap.py
                             --anndata=%(neighbour_graph_anndata)s
                             --mindist=%(mindist)s
                             --outdir=%(outdir)s
                             &> %(mindist_log_file)s
                     ''' % dict(PARAMS, **SPEC, **locals())

        statements.append(statement)

    P.run(statements)
    IOTools.touch_file(outfile)

#endregion

#region UMAP plots

# ########################################################################### #
# ################## Set the DR visualisation method ######################## #
# ########################################################################### #

# Used to show clusters, factors of interest and gene expression levels
# in various downstream functions

RDIMS_VIS_TASK = UMAP
RDIMS_VIS_METHOD = "umap"
RDIMS_VIS_COMP_1 = "UMAP_1"
RDIMS_VIS_COMP_2 = "UMAP_2"


# ########################################################################### #
# ###### Visualise gene expression across cells in reduced dimensions ####### #
# ########################################################################### #

@transform(RDIMS_VIS_TASK,
           regex(r"(.*)/(.*)/(.*).sentinel"),
           add_inputs(metadata),
           r"\1/rdims.visualisation.dir/plot.rdims.factor.sentinel")
def plotRdimsFactors(infiles, outfile):
    '''
       Visualise factors of interest on the UMAP.
    '''

    infile, export_sentinel = infiles

    metadata_table = os.path.join(os.path.dirname(export_sentinel),
                                  "metadata.tsv.gz")

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    rdims_table = infile.replace(".sentinel",
                                 "." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

    color_factors = []

    if PARAMS["plot_qcvars"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_qcvars"].split(",")]

    if PARAMS["plot_groups"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_groups"].split(",")]

    if PARAMS["plot_subgroup"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_subgroup"].split(",")]

    color_factors = [ x for x in color_factors if x != "cluster" ]

    # ensure list is unique whilst preserving order.
    color_factors = list(dict.fromkeys(color_factors))

    color_factors = "--colorfactors=" + ",".join(color_factors)

    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    # bring vars into local scope..
    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_rdims_factor.R
                   --method=%(rdims_vis_method)s
                   --table=%(rdims_table)s
                   --metadata=%(metadata_table)s
                   --rdim1=%(rdim1)s
                   --rdim2=%(rdim2)s
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --pointpch=%(plot_pointpch)s
                   --pdf=%(plot_pdf)s
                   --outdir=%(outdir)s
                   --plotdirvar=rdimsVisFactorDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)

    tex_file = os.path.join(spec.outdir, "plot.rdims.factor.tex")

    with open(tex_file, "w") as tex:
        tex.write("\input{" + os.path.join(spec.outdir) + "/umap}")

    IOTools.touch_file(outfile)


@follows(RDIMS_VIS_TASK)
@transform(cluster,
           regex(r"(.*)/(.*)/(.*).sentinel"),
           r"\1/\2/rdims.visualisation.dir/plot.rdims.cluster.sentinel")
def plotRdimsClusters(infile, outfile):
    '''
        Visualise the clusters on the UMAP
    '''

    metadata_table = os.path.join(os.path.dirname(infile),
                                  "cluster_ids.tsv.gz")

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    print("******")
    print(spec)

    color_factors = "--colorfactors=cluster_id"

    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    # bring vars into local scope..
    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])


    mindists = [x.strip() for x in PARAMS["umap_mindists"].split(",")]

    statements = []
    for mindist in mindists:

        rdims_table = os.path.join(spec.component_dir,
                                   "umap.dir",
                                   "umap." + mindist + ".tsv.gz")

        umap_spec = "umap.mindist_" + mindist

        mindist_log_file = outfile.replace(".sentinel",
                                           "." + mindist + ".log")

        statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_rdims_factor.R
                   --method=%(umap_spec)s
                   --table=%(rdims_table)s
                   --metadata=%(metadata_table)s
                   --rdim1=%(rdim1)s
                   --rdim2=%(rdim2)s
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --pointpch=%(plot_pointpch)s
                   --pdf=%(plot_pdf)s
                   --outdir=%(outdir)s
                   --plotdirvar=rdimsVisClusterDir
                   &> %(mindist_log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

        statements.append(statement)
    P.run(statements)

    tex_file = os.path.join(spec.outdir, "plot.rdims.factor.tex")

    with open(tex_file, "w") as tex:
        for mindist in mindists:
            tex.write("\input{" + spec.outdir + "/umap.mindist_" + mindist + "}\n")

    IOTools.touch_file(outfile)


@active_if(PARAMS["run_singleR"])
@transform(RDIMS_VIS_TASK,
           regex(r"(.*)/(.*)/(.*).sentinel"),
           r"\1/singleR.dir/rdims.plots.sentinel")
def plotRdimsSingleR(infile, outfile):
    '''
        Plot the SingleR primary identity assignments on a UMAP
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    rdims_table = os.path.join(spec.component_dir,
                               "umap.dir",
                               "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

    # bring vars into local scope..
    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"])
    
    api_loc = os.path.join(PARAMS["source_cellhub"], "api", "singleR")

    if not os.path.exists(api_loc):
        raise ValueError("singleR api not found in source cellhub folder")

    references = [os.path.basename(x) for x in
                  glob.glob(os.path.join(api_loc,"*"))]
    
    stats = []
    
    for reference in references:
    
        labels = os.path.join(api_loc, reference, "labels.tsv.gz")
    
        statement  = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_rdims_factor.R
                        --method=%(rdims_vis_method)s
                        --table=%(rdims_table)s
                        --metadata=%(labels)s
                        --rdim1=%(rdim1)s
                        --rdim2=%(rdim2)s
                        --colorfactors=pruned.labels
                        --analysisname=%(reference)s
                        --pointsize=%(plot_pointsize)s
                        --pointalpha=%(plot_pointalpha)s
                        --pointpch=%(plot_pointpch)s
                        --pdf=%(plot_pdf)s
                        --outdir=%(outdir)s
                        --plotdirvar=rdimsVisSingleRDir
                        &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())
                
        stats.append(statement)

    P.run(stats)
    IOTools.touch_file(outfile)



@follows(RDIMS_VIS_TASK)
@active_if(PARAMS["run_exprsreport"] and not PARAMS["run_marker_report"])
@transform(scanpyCluster,
           regex(r"(.*)/cluster.sentinel"),
           r"\1/genelists.dir/plot.rdims.genes.sentinel")
def plotRdimsGenes(infile, outfile):
    '''
        Visualise gene expression levels on the UMAP.
    '''

    # TODO: test and fix.

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    tex_path = os.path.join(spec.outdir, "plot.rdims.known.genes.tex")

    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    rdims_table = os.path.join(spec.component_dir,
                               "umap.dir",
                               "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")


    if PARAMS["exprsreport_genelists"]:
        genelists = glob.glob(
            os.path.join(PARAMS["exprsreport_genelist_dir"], "*.tsv"))

        rdims_table = infile.replace( ".sentinel", ".tsv")

        # set the job threads and memory
        job_threads, job_memory, r_memory = TASK.get_resources(
            memory=PARAMS["resources_memory_standard"],
            cpu=PARAMS["resources_numcores"])

        for genelist in genelists:

            fname = "plot.rdims.genes." + os.path.basename(genelist) + ".log"
            log_file = os.path.join(outdir, fname)

            if PARAMS["plot_shape"] is not None:
                shape = "--shapefactor=%(plot_shape)s" % PARAMS
            else:
                shape = ""

            statement = '''Rscript %(cellhub_code_dir)s/R/plot_rdims_gene.R
                           --method=%(rdims_vis_method)s
                           --table=%(rdims_table)s
                           --seuratobject=%(seurat_object)s
                           --seuratassay=RNA
                           --rdim1=%(rdim1)s
                           --rdim2=%(rdim2)s
                           %(shape)s
                           --genetable=%(genelist)s
                           --pointsize=%(plot_pointsize)s
                           --pointalpha=%(plot_pointalpha)s
                           --maxcells=%(plot_maxcells)s
                           --outdir=%(outdir)s
                           --pdf=%(plot_pdf)s
                           --plotdirvar=genelistsDir
                           --workers=%(exprsreport_workers)s
                           &> %(log_file)s
                       ''' % dict(PARAMS, **SPEC, **locals())

            P.run(statement)

        # prepare a summary tex snippet for inclusion in the report.

        with(open(tex_path, "w")) as tex:

            for genelist in genelists:

                texf = os.path.join(
                    outdir,
                    "plot.rdims.genes." +
                    os.path.basename(genelist).replace(".tsv", ""))

                gsname = os.path.basename(
                    genelist)[:-len(".tsv")].replace("_", "\\_")

                tex.write(
                    "\\subsection{Expression of known genes: %s}\n" % gsname)
                tex.write(
                    "\\input{%(texf)s}\n" % locals())

            tex.write("\n")

    else:

        with(open(tex_path, "w")) as tex:

            tex.write("No genelists were specified.\n")
            tex.write("\n")

    IOTools.touch_file(outfile)


#endregion

#region singleR

@active_if(PARAMS["run_singleR"])
@transform(metadata,
           regex(".*/metadata.sentinel"),
           "singleR.dir/singleR.plots.sentinel")
def plotSingleR(infile, outfile):
    '''
       Make singleR heatmaps for the references present on the cellhub API.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    metadata = infile.replace(".sentinel", ".tsv.gz")
    api_loc = os.path.join(PARAMS["source_cellhub"], "api", "singleR")

    if not os.path.exists(api_loc):
        raise ValueError("singleR api not found in source cellhub folder")

    references = [os.path.basename(x) for x in
                  glob.glob(os.path.join(api_loc,"*"))]
    
    stats = []
    
    for reference in references:
    
        # set the job threads and memory
        job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"])
        
        scores = os.path.join(api_loc, reference, "scores.tsv.gz")
        labels = os.path.join(api_loc, reference, "labels.tsv.gz")

        statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_singleR_plots.R
                       --metadata=%(metadata)s
                       --scores=%(scores)s
                       --labels=%(labels)s
                       --reference=%(reference)s
                       --outdir=%(outdir)s
                       --pdf=%(plot_pdf)s
                       &> %(log_file)s
                       ''' % dict(PARAMS, **SPEC, **locals())

        stats.append(statement)

    P.run(stats)
    IOTools.touch_file(outfile)

@active_if(PARAMS["run_singleR"])
@follows(plotSingleR, plotRdimsSingleR)
@transform(UMAP,
           regex(r"(.*)/umap.dir/umap.sentinel"),
           r"\1/singleR.dir/summary.sentinel")
def summariseSingleR(infile, outfile):
    '''
       Collect the single R plots into a section for the Summary report.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)
    
    api_loc = os.path.join(PARAMS["source_cellhub"], "api", "singleR")

    references = [os.path.basename(x) for x in
                  glob.glob(os.path.join(api_loc,"*"))]

    singleR_path = "singleR.dir"

    singleR_umap_path = os.path.join(Path(infile).parents[1],
                                "singleR.dir")

    latex_path = outfile.replace(".sentinel", ".tex")

    with open(latex_path, "w") as tex:

        for reference in references:

            # heatmap
            tex.write(templates.subsection % {"title": reference})
            tex.write("\n")

            heatmap_path = os.path.join(singleR_path,
                                        reference + ".heatmap")


            if(os.path.exists(heatmap_path + ".png")):
                heatmap_fig = {"width": "1", "height": "0.9",
                               "path": heatmap_path,
                               "caption": "singleR predictions (" +\
                               reference + ")"}

                tex.write(textwrap.dedent(
                    templates.figure % heatmap_fig))
                tex.write("\n")

            umap_path = os.path.join(singleR_umap_path,
                                     "umap." + reference + ".pruned.labels")

            if(os.path.exists(umap_path + ".png")):

                umap_fig = {"width": "1", "height": "0.9",
                            "path": umap_path,
                            "caption": "pruned singleR predictions (" +\
                            reference + ")"}

                tex.write(textwrap.dedent(
                    templates.figure % umap_fig))

                tex.write("\n")
                
    IOTools.touch_file(outfile)

#endregion

#region Stats

# ########################################################################### #
# ################# plot per-cluster summary statistics ##################### #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.sentinel"),
           add_inputs(metadata),
           r"\1/group.numbers.dir/plot.group.numbers.sentinel")
def plotGroupNumbers(infiles, outfile):
    '''
       Plot statistics on cells by group, e.g. numbers of cells per cluster.

       Plots are defined on a case-by-case basis in the yaml.
    '''

    cluster_outfile, metadata_outfile = infiles

    spec, SPEC = TASK.get_vars(cluster_outfile, outfile, PARAMS)

    metadata_table = metadata_outfile.replace(".sentinel", ".tsv.gz")

    # we need the yaml as a dict, so...
    config_file = "pipeline_cluster.yml"
    if not os.path.exists(config_file):
        config_file = "%s/pipeline_cluster.yml" % os.path.splitext(__file__)[0]
        if not os.path.exists(config_file):
            raise ValueError("Config file not found in plot group numbers")

    with open(config_file) as f:
        params = yaml.load(f, Loader=yaml.FullLoader)

    params = params["summaries"]

    statements = []
    for summary_key in params.keys():

        summary = params[summary_key].copy()

        options = []

        # populate the Rscript options from the yaml dictionary
        for k, v in summary.items():
            if v == "None" or v == None or v == False or k == "title":
                pass
            elif v == True:
                options.append("--" + k)
            elif k in ["xlab", "ylab"]:
                options.append("--" + k + "=\"" + str(v) + "\"")
            else:
                options.append("--" + k + "=" + str(v))

        options = "\n".join(options)

        SPEC["log_file"] = os.path.join(spec.outdir, summary_key + ".log")

        job_threads, job_memory, r_memory = TASK.get_resources(
            memory=PARAMS["resources_memory_min"])

        statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_group_numbers.R
                   --metadata=%(metadata_table)s
                   --clusters=%(cluster_ids)s
                   --title=%(summary_key)s
                   %(options)s
                   --outdir=%(outdir)s
                   --plotdirvar=groupNumbersDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

        statements.append(statement)

    P.run(statements)

    # write out the latex snippet...
    with open(os.path.join(spec.outdir, "number.plots.tex"),"w") as tex:

        for fig in params.keys():

            if("_" in params[fig]["title"]):
               raise ValueError("Underscores are not allowed in the plot"
                                " titles (due to issues with latex...")

            # Add the figures, one per subsection, escaping underscores.
            tex.write(templates.subsection %
                      {"title": params[fig]["title"]})

            tex.write("\n")

            fig_path = os.path.join(spec.outdir, fig)

            if(os.path.exists(fig_path + ".png")):
                fig_spec = {"width": "1", "height": "0.9",
                            "path": fig_path,
                            "caption": params[fig]["title"]
                            }

                tex.write(textwrap.dedent(
                    templates.figure % fig_spec))
                tex.write("\n")

    IOTools.touch_file(outfile)


@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/stats.dir/cluster.stats.sentinel")
def clusterStats(infile, outfile):
    '''
       Compute per-cluster statistics (e.g. mean expression level).
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    if PARAMS["markers_conserved"]:

        subset_factor = PARAMS["markers_conserved_factor"]
        subset_stat="--subset_factor=" + subset_factor

        if not anndata in sys.modules:
            import anndata as ad

        adata = ad.read_h5ad(PARAMS["source_anndata"])
        subset_levels = [x for x in adata.obs[subset_factor].cat.categories]

    else:
        subset_stat=""
        subset_levels = ["all"]
    
    statements = []
    for subset_level in subset_levels:

        outfile_name = os.path.join(spec.outdir, 
                                    ".".join([subset_level, "stats.tsv.gz"]))
        log_file_name = outfile_name.replace(".tsv.gz", ".log")

        stat = '''python %(cellhub_code_dir)s/python/cluster_stats.py
                            --anndata=%(source_anndata)s
                            %(subset_stat)s
                            --subset_level=%(subset_level)s
                            --clusterids=%(cluster_ids)s
                            --outfile=%(outfile_name)s
                            &> %(log_file_name)s
                    ''' % dict(PARAMS, **SPEC, **locals())
    
        statements.append(stat)

    P.run(statements)
    IOTools.touch_file(outfile)

#endregion

#region Cluster Markers

# ########################################################################### #
# ############# Cluster marker identification and visualisation ############# #
# ########################################################################### #

@follows(clusterStats)
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           r"\1/\2/markers.dir/markers.sentinel")
def findMarkers(infile, outfile):
    '''
        Find per-cluster marker genes. Just execute the rank_genes_groups routine, 
        no filtering here.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)
    
    statements = []
    
    for i in spec.clusters:
    
        if str(i) == "911":
            continue

        if PARAMS["markers_conserved"]:

            subset_factor = PARAMS["markers_conserved_factor"]
            subset_stat="--subset_factor=" + subset_factor

            if not anndata in sys.modules:
                import anndata as ad

            adata = ad.read_h5ad(PARAMS["source_anndata"])
            subset_levels = [x for x in adata.obs[subset_factor].cat.categories]
            
        else:
            subset_stat = ""
            subset_levels = ["all"]
            
        
        for subset_level in subset_levels:

            #outdir = os.path.join(spec.outdir, subset_level + ".level.dir")

            outfile_name = os.path.join(spec.outdir, 
                                        ".".join([str(i), subset_level, "markers.tsv.gz"]))
            
            log_file_name = outfile_name.replace(".tsv.gz", ".log")
            
            stats_file = os.path.join(spec.cluster_dir,
                                      "stats.dir",
                                      subset_level + ".stats.tsv.gz")
            
            sizes_file = os.path.join(spec.cluster_dir,
                                      "stats.dir",
                                      subset_level + ".sizes.tsv.gz")

            stat = '''python %(cellhub_code_dir)s/python/cluster_markers.py
                            --anndata=%(source_anndata)s
                            %(subset_stat)s
                            --subset_level=%(subset_level)s
                            --clusterids=%(cluster_ids)s
                            --cluster=%(i)s
                            --group_means=%(stats_file)s
                            --group_sizes=%(sizes_file)s
                            --method=%(markers_test)s
                            --pseudocount=%(markers_pseudocount)s
                            --outfile=%(outfile_name)s
                            &> %(log_file_name)s
                    ''' % dict(PARAMS, **SPEC, **locals())
            

            statements.append(stat)

    P.run(statements)
    IOTools.touch_file(outfile)


@follows(findMarkers)
@transform(cluster,
           regex(r"(.*)/(.*)/cluster.sentinel"),
           add_inputs(loom, metadata),
           r"\1/\2/markers.dir/markers.summary.sentinel")
def summariseMarkers(infiles, outfile):
    '''
       Summarise the differentially expressed marker genes. P-values
       are adjusted per-cluster are filtering out genes with low expression
       levels and fold changes. Per-cluster gene universes are prepared for
       the pathway analysis.
    '''

    spec, SPEC = TASK.get_vars(infiles[0], outfile, PARAMS)
    
    cluster_sentinel, loom, metadata = infiles
    
    loom_file = loom.replace(".sentinel", ".loom")
    metadata_file= metadata.replace(".sentinel", ".tsv.gz")
    
    marker_files = glob.glob(os.path.join(spec.outdir, "*.markers.tsv.gz"))
    
    print(marker_files)
    marker_files = ",".join(marker_files)
    
    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_summarise_markers.R
                   --marker_files=%(marker_files)s
                   --minpct=%(markers_min_pct)s
                   --minfc=%(markers_min_fc)s
                   --clusterids=%(cluster_ids)s
                   --annotation=%(cellhub_ensembl_annotations)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())
                
    
    P.run(statement)
    IOTools.touch_file(outfile)

#endregion

#region Plot Cluster Markers

@active_if(PARAMS["run_top_marker_heatmap"])
@transform(summariseMarkers,
           regex(r"(.*)/(.*)/(.*)/markers.summary.sentinel"),
           add_inputs(loom, metadata),
           r"\1/\2/\3/topMarkerHeatmap.sentinel")
def topMarkerHeatmap(infiles, outfile):
    '''
       Make the top marker heatmap.
    '''

    markers, loom, metadata = infiles
    
    spec, SPEC = TASK.get_vars(markers, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(markers),
                                "markers.summary.table.tsv.gz")
    
    
    loom_file = loom.replace(".sentinel", ".loom")
    metadata_file= metadata.replace(".sentinel", ".tsv.gz")
    
    if PARAMS["source_heatmap_matrix"] == "X":
        matrix_loc = "matrix"
        scale= "FALSE"
    elif PARAMS["source_heatmap_matrix"] == "log1p":
        matrix_loc = "layers/log1p"
        scale = "TRUE"
    else:
        raise ValueError('source heatmap matrix parameter must be "X" or "log1p"')

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"],
        cpu=1)

    if PARAMS["plot_subgroup"] is not None:
        subgroup = '''--subgroup=%(plot_subgroup)s''' % PARAMS
    else:
        subgroup = ""

    statement = '''
    Rscript %(cellhub_code_dir)s/R/scripts/cluster_topMarkerHeatmap.R
                   --loom=%(loom_file)s
                   --clusterids=%(cluster_ids)s
                   --metadata=%(metadata_file)s
                   --matrix_loc=%(matrix_loc)s
                   --scale=%(scale)s
                   --markers=%(marker_table)s
                   --pdf=%(plot_pdf)s
                   %(subgroup)s
                   --outdir=%(outdir)s
                    &> %(log_file)s
                    ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_characterise_markers"])
@transform(summariseMarkers,
           regex(r"(.*)/markers.dir/markers.summary.sentinel"),
           r"\1/de.plots.dir/characteriseClusterMarkers.tex")
def dePlots(infile, outfile):
    '''
        Make per-cluster diagnoistic differential expression plots
        (MA and volcano plots).
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.tsv.gz")

    # not all clusters may have degenes
    degenes = pd.read_csv(marker_table, sep="\t")

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"],
        cpu=1)

    statements = []
    tex = []

    for i in spec.clusters:

        if str(i) == "911":
            continue

        SPEC["log_file"] = outfile[:-len(".tex")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(cellhub_code_dir)s/R/scripts/cluster_de_plots.R
                    --degenes=%(marker_table)s
                    --cluster=%(i)s
                    --outdir=%(outdir)s
                    --pdf=%(plot_pdf)s
                    --plotdirvar=clusterMarkerDEPlotsDir
                    &> %(log_file)s
                    ''' % dict(PARAMS, **SPEC, **locals())

        cluster_tex_file = ".".join(["characterise.degenes", str(i), "tex"])
        tex.append("\\input{\\clusterMarkerDEPlotsDir/" + cluster_tex_file + "}")
        statements.append(statement)

    P.run(statements)

    with open(outfile, "w") as out_tex:
        for line in tex:
            out_tex.write(line + "\n")


@transform(summariseMarkers,
           regex(r"(.*)/markers.dir/markers.summary.sentinel"),
           add_inputs(loom, metadata),
           r"\1/marker.plots.dir/marker.plots.sentinel")
def markerPlots(infiles, outfile):
    '''
       Make the per-cluster marker plots
       TODO: add some version of split dot plots back.. 
    '''

    markers, loom, metadata = infiles

    spec, SPEC = TASK.get_vars(markers, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(markers),
                                "markers.summary.table.tsv.gz")

    # not all clusters may have degenes
    markers = pd.read_csv(marker_table, sep="\t")
    clusters_with_markers = [x for x in markers.cluster.unique()]
    
    loom_file = loom.replace(".sentinel", ".loom")
    metadata_file= metadata.replace(".sentinel", ".tsv.gz")
    
    if PARAMS["source_heatmap_matrix"] == "X":
        scaled_matrix_loc = "matrix"
        scale= "FALSE"
    elif PARAMS["source_heatmap_matrix"] == "log1p":
        scaled_matrix_loc = "layers/log1p"
        scale = "TRUE"
    else:
        raise ValueError('source heatmap matrix parameter must be "X" or "log1p"')

    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"],
        cpu=1)

    statements = []

    rdims_table = os.path.join(spec.component_dir,
                               "umap.dir",
                               "umap." + str(PARAMS["umap_mindist"]) + ".tsv.gz")

    if PARAMS["plot_subgroup"] is not None:
        group_opt = "--group=" + PARAMS["plot_subgroup"]
    else:
        group_opt = ""

    for i in clusters_with_markers:

        if str(i) == "911":
            continue

        SPEC["log_file"] = outfile[:-len(".sentinel")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(cellhub_code_dir)s/R/scripts/cluster_marker_plots.R
                    --markers=%(marker_table)s
                    --loom=%(loom_file)s
                    --scaled_matrix_loc="matrix"
                    --data_matrix_loc="layers/log1p"
                    --scale=%(scale)s
                    --metadata=%(metadata_file)s
                    --annotation=%(cellhub_ensembl_annotations)s
                    --clusterids=%(cluster_ids)s
                    --rdimstable=%(rdims_table)s
                    --cluster=%(i)s
                    --outdir=%(outdir)s
                    %(group_opt)s
                    --pdf=%(plot_pdf)s
                    &> %(log_file)s
                    ''' % dict(PARAMS, **SPEC, **locals())

        statements.append(statement)

    P.run(statements)

    IOTools.touch_file(outfile)


@transform(summariseMarkers,
           regex(r"(.*)/markers.dir/(.*).sentinel"),
           r"\1/marker.de.plots.dir/plotMarkerNumbers.sentinel")
def plotMarkerNumbers(infile, outfile):
    '''
       Summarise the numbers of marker genes for each cluster.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.tsv.gz")

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_plot_marker_numbers.R
                   --degenes=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   --minfc=2
                   --minpadj=0.05
                   --plotdirvar=clusterMarkerDEPlotsDir
                   &> %(log_file)s
                ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

#endregion

#region Markers <Target>

# ########################################################################### #
# ########### marker gene (and within cluster DE) analysis ################## #
# ########################################################################### #

@follows(#characteriseClusterMarkers,
         topMarkerHeatmap,
         plotMarkerNumbers,
         dePlots,
         markerPlots)
@files(None, "markers.sentinel")
def markers(infile, outfile):
    '''
       Target to run marker gene plotting tasks.
    '''

    IOTools.touch_file(outfile)

#endregion

#region Geneset Analysis

# ########################################################################### #
# ######################### Geneset Analysis ################################ #
# ########################################################################### #

def parseGMTs(param_keys=["gmt_pathway_files_"]):
    '''
       Helper function for parsing the lists of GMT files
    '''

    all_files = []
    all_names = []

    for param_key in param_keys:


        gmts = [x for x in PARAMS.keys()
                if x.startswith(param_key)]

        if len(gmts) > 0:
            all_files += [PARAMS[x] for x in gmts]

            all_names += [x.replace(param_key, "")
                              for x in gmts]

    if len(all_files) == 0:
        all_files = "none"
        all_names = "none"
    else:
        all_files = ",".join(all_files)
        all_names = ",".join(all_names)

    return all_names, all_files


# ------------------- < between cluster geneset analysis > ------------------ #

@active_if(PARAMS["run_genesets"])
@follows(summariseMarkers)
@transform(findMarkers,
           regex(r"(.*)/markers.dir/markers.sentinel"),
           r"\1/genesets.dir/geneset.analysis.sentinel")
def genesetAnalysis(infile, outfile):
    '''
    Naive geneset over-enrichment analysis of cluster marker genes.

    Testing is performed with the gsfisher package.

    GO categories and KEGG pathways are tested by default.

    Arbitrary sets of genes cat be supplied as GMT files
    (e.g. such as those from MSigDB).
    '''

    findMarkersLog = infile

    spec, SPEC = TASK.get_vars(findMarkersLog, outfile, PARAMS)

    param_keys = ["gmt_celltype_files_",
                  "gmt_pathway_files_"]
    gmt_names, gmt_files = parseGMTs(param_keys=param_keys)

    statements = []

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    for i in spec.clusters:

        if str(i) == "911":
            continue

        cluster_log_file = os.path.join(spec.outdir, "geneset.analysis." + str(i) + ".log")

        markers = os.path.join(spec.indir, "markers.summary.table.tsv.gz")

        universe = os.path.join(
            spec.indir, str(i) + ".universe.tsv.gz")

        if not os.path.exists(universe):
            E.warn("Skipping geneset analysis: %s does not exist" % universe)
            continue

        statements.append('''Rscript %(cellhub_code_dir)s/R/scripts/cluster_geneset_analysis.R
                            --markers=%(markers)s
                            --universe=%(universe)s
                            --species=%(source_species)s
                            --annotation=%(cellhub_ensembl_annotations)s
                            --kegg_pathways=%(cellhub_kegg_pathways)s
                            --gmt_names=%(gmt_names)s
                            --gmt_files=%(gmt_files)s
                            --cluster=%(i)s
                            --adjpthreshold=%(genesets_marker_adjpthreshold)s
                            --direction=positive
                            --outdir=%(outdir)s
                            &> %(cluster_log_file)s
                      ''' % dict(PARAMS, **SPEC, **locals()))

    P.run(statements)
    IOTools.touch_file(outfile)


@active_if(PARAMS["run_genesets"])
@transform(genesetAnalysis,
           regex(r"(.*)/geneset.analysis.sentinel"),
           r"\1/summarise.geneset.analysis.sentinel")
def summariseGenesetAnalysis(infile, outfile):
    '''
    Summarise the geneset over-enrichment analyses of cluster marker genes.

    Enriched pathways are saved as dotplots and exported in excel format.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    # need to sort out the dependencies properly!
    genesetdir = os.path.dirname(infile)

    param_keys = ["gmt_celltype_files_",
                  "gmt_pathway_files_"]
    gmt_names, gmt_files = parseGMTs(param_keys=param_keys)

    # Read clusters

    use_adjusted = str(PARAMS["genesets_use_adjusted_pvalues"]).upper()
    show_common = str(PARAMS["genesets_show_common"]).upper()

    show_detailed = str(PARAMS["genesets_show_detailed"])

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_min"])

    statement = '''Rscript %(cellhub_code_dir)s/R/scripts/cluster_geneset_summary.R
                         --genesetdir=%(genesetdir)s
                         --gmt_names=%(gmt_names)s
                         --show_detailed=%(show_detailed)s
                         --clusters=%(cluster_table)s
                         --mingenes=%(genesets_min_fg_genes)s
                         --pvaluethreshold=%(genesets_pvalue_threshold)s
                         --padjustmethod=%(genesets_padjust_method)s
                         --useadjusted=%(use_adjusted)s
                         --minoddsratio=%(genesets_min_odds_ratio)s
                         --showcommon=%(show_common)s
                         --outprefix=%(outdir)s/cluster.genesets
                         --prefix=genesets
                         --plotdirvar=clusterGenesetsDir
                         --pdf=%(plot_pdf)s
                    &> %(log_file)s
                      ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)

#endregion

#region Genesets <Target>

# ---------------------- < geneset analysis target > ---------------------- #

@files([summariseGenesetAnalysis],
       "genesets.sentinel")
def genesets(infile, outfile):
    '''
       Intermediate target to run geneset tasks
    '''

    IOTools.touch_file(outfile)

#endregion

#region Plots <Target>

# ########################################################################### #
# ##################### Target to collect plots ############################# #
# ########################################################################### #

@files([
         summariseSingleR,
         compareClusters,
         clustree,
         paga,
         plotRdimsFactors,
         plotRdimsClusters,
         plotRdimsGenes,
         plotRdimsSingleR,
         plotGroupNumbers,
         dePlots,
         markerPlots], "plots.sentinel")
def plots(infile, outfile):
    '''
       Target to run all the plotting functions.
    '''

    IOTools.touch_file(outfile)

#endregion

#region Report Variables

# ########################################################################### #
# ################## PDF report generation (via Latex) ###################### #
# ########################################################################### #

# High quality pdf reports are generated which can be easily shared.
#
# The reports incorporate raster (png) graphics. PDF versions of each graphic
# can also be generation (see yaml.)

# -------------------------- < Define variables > --------------------------- #

@transform(plotRdimsClusters,
           regex("(.*)/rdims.visualisation.dir/plot.rdims.cluster.sentinel"),
           add_inputs(taskSummary, markers, genesets, plots, 
                      summariseGenesetAnalysis,summariseSingleR),
           r"\1/latex.dir/report.vars.sentinel")
def latexVars(infiles, outfile):
    '''
       Prepare a file containing the latex variable definitions for the reports.
    '''
    infile = infiles[0]
     
    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    #log_file = outfile.replace(".sty",".log")
    outfile_name = outfile.replace(".sentinel",".sty")

    statement = '''python %(cellhub_code_dir)s/python/cluster_report_vars.py
                            --infile=%(infile)s
                            --outfile=%(outfile_name)s
                            &> %(log_file)s
                    ''' % dict(**PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)
    
#endregion

#region Summary Report

# ----------------------------- < Summary report > --------------------------- #

@transform(latexVars,
           regex("(.*)/report.vars.sentinel"),
           r"\1/summary.report.sentinel")
def summaryReportSource(infile, outfile):
    '''
       Write the latex source for the summary report.
    '''
    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    #log_file = outfile.replace(".tex", ".log")
    latex_vars = infile.replace(".sentinel", ".sty")
    outfile_name = outfile.replace(".sentinel", ".tex")
    
    statement = '''python %(cellhub_code_dir)s/python/cluster_summary_report.py
                            --latexvars=%(latex_vars)s
                            --outfile=%(outfile_name)s
                            &> %(log_file)s
                    ''' % dict(**PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@transform(summaryReportSource,
           regex("(.*)/summary.report.sentinel"),
           r"\1/summaryReport.sentinel")
def summaryReport(infile, outfile):
    '''
       Compile the summary report to PDF format.
    '''
     
    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)
    
    compilation_dir = os.path.join(spec.outdir, 
                                   "summary.report.dir")
    
    out_pdf = os.path.basename(infile).replace(".sentinel",".pdf")
    
    try:
        shutil.rmtree(compilation_dir)
    except FileNotFoundError:
        pass

    os.mkdir(compilation_dir)

    source_tex = infile.replace(".sentinel", ".tex")
    log_file = outfile.replace(".sentinel", ".log")

    statement = ''' pdflatex -output-directory=%(compilation_dir)s
                             %(draft_mode)s
                             %(source_tex)s
                    &> %(log_file)s
                ''' 
                
    # Deliberately run twice - necessary for LaTeX compilation..
    draft_mode = "-draftmode"
    P.run(statement)

    draft_mode = ""
    P.run(statement)
   
    outfile_name = outfile.replace(".sentinel", ".pdf")
   
   # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, out_pdf),
            outfile_name)

    IOTools.touch_file(outfile)

#endregion

#region Marker Report

# ------------------------------ < Marker report > --------------------------- #


@follows(markerPlots, summariseMarkers)
@transform(latexVars,
           regex("(.*)/report.vars.sentinel"),
           r"\1/marker.report.sentinel")
def markerReportSource(infile, outfile):
    '''
       Write the latex source file  for the marker report.
    '''
    
    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    marker_table = os.path.join(spec.cluster_dir,
                            "markers.dir",
                            "markers.summary.table.tsv.gz")

    latex_vars = infile.replace(".sentinel", ".sty")
    #log_file = outfile.replace(".tex", ".log")
    outfile_name = outfile.replace(".sentinel", ".tex")
    
    statement = '''python %(cellhub_code_dir)s/python/cluster_marker_report.py
                            --latexvars=%(latex_vars)s
                            --markers=%(marker_table)s
                            --outfile=%(outfile_name)s
                            &> %(log_file)s
                    ''' % dict(**PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


@transform(markerReportSource,
           regex("(.*)/marker.report.sentinel"),
           r"\1/clusterMarkerReport.sentinel")
def markerReport(infile, outfile):
    '''
       Prepare a PDF report visualising the discovered cluster markers.
    '''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)
    
    compilation_dir = os.path.join(spec.outdir, 
                                   "marker.report.dir")
    
    out_pdf = os.path.basename(infile).replace(".sentinel",".pdf")
    
    try:
        shutil.rmtree(compilation_dir)
    except FileNotFoundError:
        pass

    os.mkdir(compilation_dir)

    source_tex = infile.replace(".sentinel", ".tex")
    log_file = outfile.replace(".sentinel", ".log")

    statement = ''' pdflatex -output-directory=%(compilation_dir)s
                             %(draft_mode)s
                             %(source_tex)s
                    &> %(log_file)s
                '''
    # Deliberately run twice - necessary for LaTeX compilation..
    draft_mode = "-draftmode"
    P.run(statement)

    draft_mode = ""
    P.run(statement)
    
    outfile_name = outfile.replace(".sentinel", ".pdf")
   
    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, out_pdf),
            outfile_name)
    
    IOTools.touch_file(outfile)


# endregion

#region Export Reports

@follows(mkdir("reports.dir"), markerReport)
@transform(summaryReport,
           regex(r"out.(.*).comp.dir/cluster.(.*).dir/latex.dir/summaryReport.sentinel"),
           r"reports.dir/\1.comps.\2.res/export.sentinel")
def export(infile, outfile):
    '''
       Link output files to a directory in the "reports.dir" folder.

       Prepare folders containing the reports, differentially expressed genes
       and geneset tables for each analysis.
       
       TODO: link in the cellxgene anndata files.
    '''

    spec, SPEC = TASK.get_vars(infile, infile, PARAMS)

    out_dir = Path(outfile).parents[0]

    run_dir = Path(infile).parents[1]

    try:
        shutil.rmtree(out_dir)
    except FileNotFoundError:
        pass

    os.mkdir(out_dir)

    between_xlsx = "markers.between." + \
                   str(PARAMS["findmarkers_between_testfactor"]) + \
                   ".summary.table.xlsx"

    targets = [os.path.join(run_dir,"latex.dir","summaryReport.pdf"),
               os.path.join(run_dir,"latex.dir","clusterMarkerReport.pdf"),
               os.path.join(run_dir,"markers.dir","markers.summary.table.xlsx"),
               os.path.join(run_dir,"condition.markers.dir",between_xlsx),
               os.path.join(run_dir, "genesets.dir","cluster.genesets.xlsx"),
               os.path.join(run_dir, "condition.genesets.dir","condition.genesets.xlsx")]

    for target_file in targets:

        print(target_file)
        if os.path.exists(target_file):
        
            target = os.path.basename(target_file)
            link_name = os.path.join(out_dir, target)

            os.symlink(os.path.relpath(target_file, start=out_dir),
                       link_name)

    IOTools.touch_file(outfile)


# --------------------------- < report target > ----------------------------- #

@follows(export)
def report():
    '''
       Target for building the reports.
    '''
    pass

#endregion

#region Additional Outputs

# ########################################################################### #
# ####################### Known gene violin plots ########################### #
# ########################################################################### #

@files(None,None)
def knownMarkerViolins(infile, outfile):
    pass

# TODO: Add back this functionality if needed.
# @active_if(PARAMS["run_knownmarkers"])
# @transform(scanpyCluster,
#            regex(r"(.*)/(.*)/(.*)/cluster.sentinel"),
#            r"\1/\2/\3/known.markers.dir/known.markers.sentinel")
# def knownMarkerViolins(infile, outfile):
#     '''
#        Make per-cluster violin plots from a given set of known marker genes.
#     '''

#     spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

#     if not os.path.exists(PARAMS["knownmarkers_file"]):
#         raise ValueError("The specified known markers file does not exist")

#     outprefix = outfile.replace(".sentinel", "")

#     # set the job threads and memory
#     job_threads, job_memory, r_memory = TASK.get_resources(
#         memory=PARAMS["resources_memory_low"])

#     statement = '''Rscript %(cellhub_code_dir)s/R/plot_violins.R
#                        --genetable=%(knownmarkers_file)s
#                        --seuratobject=%(seurat_object)s
#                        --seuratassay=RNA
#                        --clusterids=%(cluster_ids)s
#                        --outprefix=%(outprefix)s
#                        --plotdirvar=knownmarkersDir
#                        &> %(log_file)s
#         ''' % dict(PARAMS, **SPEC, **locals())

#     P.run(statement)
#     IOTools.touch_file(outfile)

# ########################################################################### #
# ##################### Generate cellxgene output ########################### #
# ########################################################################### #

@follows(markers)
@transform(UMAP,
           regex(r"(.*)/umap.dir/umap.sentinel"),
           r"\1/cellxgene.sentinel")
def cellxgene(infile, outfile):
    '''
       Export an anndata object for cellxgene.
    '''
        
    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)
    
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_low"],
        cpu=1)


    umap_path = os.path.join(os.path.dirname(infile),
                             ".".join(["umap", 
                                       str(PARAMS["umap_mindist"]), 
                                       "tsv.gz"]))

    cluster_paths = []
    cluster_names = []
    cxg_res = PARAMS["cellxgene_resolution"]
    if cxg_res == "all":

        for res in spec.resolutions:
            cluster_dir = os.path.join(spec.component_dir,
                            ".".join(["cluster", str(res), "dir"]))
            cluster_paths.append(os.path.join(cluster_dir, "cluster_ids.tsv.gz"))
            cluster_names.append("cluster_" + str(res))
    else:
       
        cluster_dir = os.path.join(spec.component_dir,
                            ".".join(["cluster", str(cxg_res), "dir"]))
        if not os.path.exists(cluster_dir):
            raise ValueError("Path to selected clustering resolution does not exist")
            
        cluster_paths.append(os.path.join(cluster_dir,"cluster_ids.tsv.gz"))
        cluster_names.append("cluster" + str(cxg_res))
        
    cluster_paths=",".join(cluster_paths)
    cluster_names=",".join(cluster_names)
    
    out_file = outfile.replace(".sentinel", ".h5ad")

    statement='''python %(cellhub_code_dir)s/python/cluster_cellxgene.py
                 --source_anndata=%(source_anndata)s
                 --annotation=%(cellhub_ensembl_map)s
                 --obs=%(cellxgene_obs)s
                 --umap=%(umap_path)s
                 --umap_facet_x=%(cellxgene_facet_umap_x)s
                 --umap_facet_y=%(cellxgene_facet_umap_y)s
                 --cluster_paths=%(cluster_paths)s
                 --cluster_names=%(cluster_names)s
                 --cluster_split=%(cellxgene_cluster_split)s
                 --adt=None
                 --outfile=%(out_file)s
    ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ######################### Auxillary functions ############################# #
# ########################################################################### #

# TODO: replace with python script to summarise counts from anndata.
# @transform(scanpyCluster,
#            regex(r"(.*)/cluster.sentinel"),
#            r"\1/cluster_counts.rds")
# def aggregateUMIsPseudobulks(infile, outfile):
#     '''
#     Aggregate UMI counts across cells within cluster to form pseudobulks.

#     Useful for performing e.g. DESeq2 analysis of clusters from
#     multiple samples.
#     '''

#     outdir = os.path.dirname(infile)
#     cluster_ids = os.path.join(outdir, "cluster_ids.rds")

#     seurat_dir = Path(outfile).parents[1]
#     sample_data_dir = str(seurat_dir).replace(".seurat", "")
#     run_dir = Path(seurat_dir).parents[0]

#     tenxdir = os.path.join(run_dir, 'data.dir', sample_data_dir)

#     log_file = os.path.join(outdir, 'aggregated_clusters.log')

#     locals().update(
#         TASK.get_resources(memory=PARAMS["resources_memory_low"]))

#     statement = '''Rscript %(cellhub_code_dir)s/R/aggregate_umis_pseudobulks.R
#                            --tenxdir=%(tenxdir)s
#                            --clusterids=%(cluster_ids)s
#                            --outfile=%(outfile)s
#                            &> %(log_file)s
#                         '''

#     P.run(statement)


#endregion

#region Full <Target> and Main

# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #


@follows(report, cellxgene)
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))

#endregion