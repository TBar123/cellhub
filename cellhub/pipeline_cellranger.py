'''
============================
pipeline_cellranger.py
============================


Overview
========

This pipeline performs the following functions:

* Alignment and quantitation of 10x GEX, CITE-seq and VDJ sequencing data.

Usage
=====

See :doc:`Installation</Installation>` and :doc:`Usage</Usage>` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline_cellranger_multi.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_cellranger_multi.py config


Inputs
------

The pipeline requires two inputs: (i) a "sample.metadata.tsv" file describing the samples 
and (ii) a "fastq.manifest.tsv" table that lists the directories containing the 
fastq files.

(i) libraries.tsv
^^^^^^^^^^^^^^^^^

This table must have the following mandatory columns:

library_id: This is assumed to be a unique identifier: all fastqs linked to a given library_id
             are merged (within feature type).
chemistry:  The options are: 'auto' for autodetection, 
                             'threeprime' for Single Cell 3', 
                             'fiveprime' for  Single Cell 5', 
                             'SC3Pv1',
                             'SC3Pv2',
                             'SC3Pv3', 
                             'SC5P-PE',
                             'SC5P-R2' for Single Cell 5', paired-end/R2-only,
                             'SC-FB' for Single Cell Antibody-only 3' v2 or 5'.
expect_cells: An integer specifying the effected number of cells
sample_name: the name of the sample from which the sequencing data were derived. 

It can then contain any additional metadata such as e.g. "tissue", "condition", "age", "sex" etc.

(ii) fastqs.tsv
^^^^^^^^^^^^^^^

This table must have the following columns:

library_id: the name of the sample from which the sequencing data were derived
path: the location of the folder containing the fastq files
feature_type: one of "Gene Expression", "Antibody Capture", "VDJ-T" or "VDJ-T"
lane: an integer denoting the sequencing lane. When samples have multiple lanes, the sequencing data is automatically combined.



Dependencies
------------

This pipeline requires:
* cgat-core: https://github.com/cgat-developers/cgat-core
* cellranger: https://support.10xgenomics.com/single-cell-gene-expression/


Pipeline output
---------------

The pipeline returns:
* the output of cellranger multi

Code
====

'''

from ruffus import *
from pathlib import Path
import sys
import os
import glob
import sqlite3
import yaml
import  csv

import cgatcore.experiment as E
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

import pandas as pd
import numpy as np

# import local pipeline utility functions
import cellhub.tasks as T
import cellhub.tasks.cellranger as cellranger
import cellhub.tasks.samples as S

# -------------------------- Pipeline Configuration -------------------------- #

# Override function to collect config files
P.control.write_config_files = T.write_config_files

# load options from the yml file
P.parameters.HAVE_INITIALIZED = False
PARAMS = P.get_parameters(T.get_parameter_file(__file__))

# set the location of the code directory
PARAMS["cellhub_code_dir"] = Path(__file__).parents[1]

# ----------------------- < helper functions > ------------------------ #


# -------------------------- Read in the samples set -------------------------- #

samples = S.init(pipeline="cellranger",
                 fastq_tsv = params["fastq_table"],
                 library_tsv = params["library_table"])




# ########################################################################### #
# ############################    run cellranger  ########################### #
# ########################################################################### #

# iterate over sample list and 


def cellranger_jobs:



@files(cellranger_jobs)
def cellranger(infile, outfile):
    '''
    Execute the cellranger count or vdj pipeline as appropriate.
    
    Use of cellranger cluster mode is not supported.
    '''

    # read id_tag from file name
    config_path = os.path.basename(infile)
    sample_basename = os.path.basename(infile)
    sample_name_sections = sample_basename.split(".")
    id_tag = sample_name_sections[0]


    #set the maximum number of jobs for cellranger
    max_jobs = PARAMS["cellranger_maxjobs"]

    ## send one job script to slurm queue which arranges cellranger run
    ## hard-coded to ensure enough resources
    job_threads = 6
    job_memory = "24G"

    log_file = id_tag + ".log"

    mempercore = PARAMS["cellranger_mempercore"]

    if mempercore:
        mempercore_stat="--mempercore " + str(mempercore)
    else:
        mempercore_stat = ""

    # this statement is to run in slurm mode
    statement = '''cd cellranger.multi.dir;
                    cellranger multi
	    	        --id %(id_tag)s
                    --csv=%(config_path)s
                    --jobmode=%(cellranger_job_template)s
                    --maxjobs=%(max_jobs)s
		            --nopreflight
                    --disable-ui
                    %(mempercore_stat)s
                    &> %(log_file)s
                 '''

    P.run(statement)
    IOTools.touch_file(outfile)


@transform(cellrangerMulti,
           regex(r"(.*)/(.*)-cellranger.multi.sentinel"),
           r"\1/register.mtx.sentinel")
def mtxAPI(infile, outfile):
    '''
    Register the post-processed mtx files on the API endpoint
    
    Inputs:

    The input cellranger.multi.dir folder layout is:

    unfiltered "outs": ::
        library_id/outs/multi/count/raw_feature_bc_matrix/

    filtered "outs": :: 
        library_id/outs/per_sample_outs/sample|library_id/count/sample_feature_bc_matrix
    
    '''

    # 1. register the GEX, ADT and HTO count matrices

    x = T.api("cellranger.multi")

    mtx_template = {"barcodes": {"path":"path/to/barcodes.tsv",
                                 "format": "tsv",
                                 "description": "cell barcode file"},
                    "features": {"path":"path/to/features.tsv",
                                  "format": "tsv",
                                  "description": "features file"},
                     "matrix": {"path":"path/to/matrix.mtx",
                                 "format": "market-matrix",
                                 "description": "Market matrix file"}
                     }


    library_id = os.path.basename(infile).split("-cellranger.multi")[0]

    # 1. deal with unfiltered count data
    matrix_location = os.path.join("cellranger.multi.dir", library_id,
                                   "outs/multi/count/raw_feature_bc_matrix")

    idx = 0
    to_register = {idx:{"type":"unfiltered", 
                        "path":matrix_location, 
                        "id": library_id}}

    # 2. deal with the filtered data
    
    # 2. deal with per sample libraries
    per_sample_loc = os.path.join("cellranger.multi.dir",
                                  library_id,
                                  "outs/per_sample_outs/")

    per_sample_dirs = glob.glob(per_sample_loc + "*")

    for per_sample_dir in per_sample_dirs:

        matrix_location = os.path.join(per_sample_dir,
                                       "count/sample_filtered_feature_bc_matrix")

        sample_or_library_id = os.path.basename(per_sample_dir)

        idx += 1
        to_register[idx] = {"type":"filtered",
                            "path":matrix_location,
                            "id": sample_or_library_id}
    
    
    for key, mtx in to_register.items():

        mtx_loc = to_register[key]["path"]
        subset = to_register[key]["type"]
        id = to_register[key]["id"]

        if os.path.exists(mtx_loc):

            mtx_x = mtx_template.copy()
            mtx_x["barcodes"]["path"] = os.path.join(mtx_loc, "barcodes.tsv.gz")
            mtx_x["features"]["path"] = os.path.join(mtx_loc, "features.tsv.gz")
            mtx_x["matrix"]["path"] =  os.path.join(mtx_loc, "matrix.mtx.gz")

            x.define_dataset(analysis_name="counts",
                             data_subset=subset,
                             data_id=id,
                             data_format="mtx",
                             file_set=mtx_x,
                             analysis_description="Cellranger count GEX output")

            x.register_dataset()

    IOTools.touch_file(outfile)



@transform(cellrangerMulti,
           regex(r"(.*)/(.*)-cellranger.multi.sentinel"),
           r"\1/register.h5.sentinel")
def h5API(infile, outfile):
    '''
    Put the h5 files on the API

    Inputs:

        The input cellranger.multi.dir folder layout is:

        unfiltered "outs": ::

            library_id/outs/multi/count/raw_feature_bc_matrix/

        filtered "outs": ::

            library_id/outs/per_sample_outs/sample|library_id/count/sample_filtered_feature_bc_matrix

    '''
    x = T.api("cellranger.multi")

    out_dir = os.path.dirname(outfile)

    if not os.path.exists(out_dir):
        os.makedirs(out_dir)

    library_id = os.path.basename(infile).split("-cellranger.multi")[0]

    h5_template = {"h5": {"path":"path/to/barcodes.tsv",
                                 "format": "h5",
                                 "link_name": "data.h5",
                                 "description": "10X h5 count file"}}

    # 1. deal with unfiltered count data
    h5_location = os.path.join("cellranger.multi.dir", library_id,
                                   "outs/multi/count/raw_feature_bc_matrix.h5")

    h5_x = h5_template.copy()
    h5_x["h5"]["path"] = h5_location

    x.define_dataset(analysis_name="counts",
                     data_subset="unfiltered",
                     data_id=library_id,
                     data_format="h5",
                     file_set=h5_x,
                     analysis_description="Cellranger h5 file")


    x.register_dataset()


    # 2. deal with per sample libraries
    per_sample_loc = os.path.join("cellranger.multi.dir",
                                  library_id,
                                  "outs/per_sample_outs/")

    per_sample_dirs = glob.glob(per_sample_loc + "*")

    for per_sample_dir in per_sample_dirs:

        h5_location = os.path.join(per_sample_dir,
                                       "count/sample_filtered_feature_bc_matrix.h5")

        h5_x = h5_template.copy()
        h5_x["h5"]["path"] = h5_location

        sample_id = os.path.basename(per_sample_dir)

        x.define_dataset(analysis_name="counts",
                         data_subset="filtered",
                         data_id=sample_id,
                         data_format="h5",
                         file_set=h5_x,
                         analysis_description="Cellranger h5 file")


        x.register_dataset()

    IOTools.touch_file(outfile)


@transform(cellrangerMulti,
           regex(r"(.*)/(.*)-cellranger.multi.sentinel"),
           r"\1/out.dir/\2/post.process.vdj.sentinel")
def postProcessVDJ(infile, outfile):
    '''
    Post-process the cellranger contig annotations.

    The cellbarcodes are reformatted to the "UMI-LIBRARY_ID" syntax.

    Inputs:

        The input cellranger.multi.dir folder layout is:

        unfiltered "outs": ::
            library_id/outs/multi/vdj_[b|t]/

        filtered "outs": ::
            library_id/outs/per_sample_outs/sample|library_id/vdj_[b|t]/

    Outputs:

        This task produces:

        unfiltered: ::
            out.dir/library_id/unfiltered/vdj_[t|b]/

        filtered: ::
            out.dir/library_id/filtered/sample_id/vdj_[t|b]/

    '''


    out_dir = os.path.dirname(outfile)

    if not os.path.exists(out_dir):
        os.makedirs(out_dir)

    library_id = os.path.basename(infile).split("-cellranger.multi")[0]

    vdj_types = ["vdj_b", "vdj_t"]

    for vdj_type in vdj_types:

        if os.path.exists(os.path.join("cellranger.multi.dir", library_id,
                                       "outs/multi/", vdj_type)):

            # 1. deal with unfiltered contig assigments
            ctg_loc = os.path.join("cellranger.multi.dir", library_id,
                                   "outs/multi/",
                                   vdj_type,
                                   "all_contig_annotations.csv")

            out_loc = os.path.join("cellranger.multi.dir/out.dir/",
                                   library_id,
                                   "unfiltered",
                                   vdj_type,
                                   "all_contig_annotations.csv.gz")

            cellranger.contig_annotations(ctg_loc, out_loc, library_id)


            per_sample_loc = os.path.join("cellranger.multi.dir",
                                          library_id,
                                          "outs/per_sample_outs/")

            per_sample_dirs = glob.glob(per_sample_loc + "*")

            for per_sample_dir in per_sample_dirs:

                sample_id = os.path.basename(per_sample_dir)

                ctg_loc = os.path.join(per_sample_dir,
                                       vdj_type,
                                       "filtered_contig_annotations.csv")

                out_loc = os.path.join("cellranger.multi.dir/out.dir/",
                                       library_id,
                                       "filtered",
                                       sample_id,
                                       vdj_type,
                                       "filtered_contig_annotations.csv.gz")

                cellranger.contig_annotations(ctg_loc, out_loc, library_id)

    IOTools.touch_file(outfile)



@transform(postProcessVDJ,
           regex(r"(.*)/out.dir/(.*)/post.process.vdj.sentinel"),
           r"\1/out.dir/\2/register.vdj.sentinel")
def vdjAPI(infile, outfile):
    '''
    Register the post-processed VDJ contigfiles on the API endpoint
    '''

    x = T.api("cellranger.multi")

    vdj_template = {"contig_annotations": {"path":"path/to/annotations.csv.gz",
                                           "format": "csv",
                                           "description": "per-cell contig annotations"}}

    library_id = outfile.split("/")[-2]

    source_loc = os.path.dirname(infile)

    for data_subset in ["unfiltered", "filtered"]:

        for vdj_type in ["vdj_b", "vdj_t"]:


            if data_subset == "filtered":
                data_subset_path = data_subset + "/" + library_id
                prefix = "filtered"
            elif data_subset == "unfiltered":
                data_subset_path = data_subset
                prefix = "all"
            else:
                raise ValueError("subset not recognised")

            vdj_loc = os.path.join(source_loc,
                                   data_subset_path,
                                   vdj_type)

            if os.path.exists(vdj_loc):

                contig_file = os.path.join(vdj_loc,
                                           prefix + "_contig_annotations.csv.gz")

                vdj_x = vdj_template.copy()
                vdj_x["contig_annotations"]["path"] = contig_file

                x.define_dataset(analysis_name=vdj_type,
                          data_subset=data_subset,
                          data_id=library_id,
                          file_set=vdj_x,
                          analysis_description="cellranger contig annotations")

                x.register_dataset()

#
# ---------------------------------------------------
# Generic pipeline tasks

@follows(cellrangerMulti, 
         mtxAPI, h5API, vdjAPI)
def full():
    '''
    Run the full pipeline.
    '''
    pass


@follows(mtxAPI, h5API)
@files(None,"use.cellranger.sentinel")
def useCounts(infile, outfile):
    '''
        Set the cellranger counts as the source for downstream analysis.
        This task is not run by default.
    '''
    
    if os.path.exists("api/counts"):
        raise ValueError("Counts have already been registered to the API")

    else:
        os.symlink("cellranger.multi/counts", "api/counts")


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
