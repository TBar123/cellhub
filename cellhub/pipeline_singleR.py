"""=============
Pipeline singleR
================

Overview
========

This pipeline performs clustering of integrated single cell data.

Usage
=====

See :doc:`Installation</Installation>` and :doc:`Usage</Usage>` on general
information how to use CGAT pipelines.

Configuration
-------------

It is recommended to perform the clustering in a new directory.

The pipeline requires a configured :file:`pipeline_cluster.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_cluster.py config


Inputs
------

The pipeline starts from an anndata object with the following structure.

* anndata.X -> scaled data
* anndata.layers["counts"] -> raw counts
* anndata.layers["log1p"] -> total count normalised, 1og1p transformed data
* anndata.obs -> metadata (typically passed through from original cellhub object)
* anndata.obsm["X_rdim_name"] -> where "rdim_name" matches the "runspec_rdim_name" parameter

It is strongly recommended to retain the information for all of the genes
in all of the matrices (i.e. do not subset to HVGs!)

Dependencies
------------

This pipeline requires:


Pipeline output
===============

The pipeline produces the following outputs:


"""

import os
import sys
import gzip
from shutil import copyfile

from pathlib import Path
import pandas as pd
from ruffus import *
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

import cellhub.tasks.control as C
import cellhub.tasks.TASK as TASK
import cellhub.tasks.fetch_cells as fetch_cells

# Override function to collect config files
P.control.write_config_files = C.write_config_files


# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline_cluster.yml" % os.path.splitext(__file__)[0],
     "../pipeline_cluster.yml",
     "pipeline_cluster.yml"])

# set the location of the code directory
PARAMS["cellhub_code_dir"] = Path(__file__).parents[1]


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))

# ------------------------------ < functions > ------------------------------ #

# ########################################################################### #
# ############################# pipeline tasks ############################## #
# ########################################################################### #

@files(None, "task.summary.table.tex")
def taskSummary(infile, outfile):
    '''Make a summary of optional tasks that will be run'''

    tasks, run = [], []

    for k,v in PARAMS.items():
        if k.startswith("run_"):
            tasks.append(k[4:])
            run.append(str(v))

    tab = pd.DataFrame(list(zip(tasks,run)),columns=["task","run"])
    print(tab)

    tab.to_latex(buf=outfile, index=False)


################################################################### #
# ############### Predict cell-types using singleR ################### #
# #################################################################### #

def genSingleRjobs():
    '''generate the singleR jobs'''

    seurat_objects = glob.glob("*.seurat.dir/begin.rds")

    references = [x.strip() for x in PARAMS["singleR_reference"].split(",")]

    for seurat_object in seurat_objects:

        seurat_dir = os.path.dirname(seurat_object)

        for reference in references:

            yield [seurat_object,
                   os.path.join(seurat_dir,
                                "singleR.dir",
                                reference + ".ref.dir",
                                "singleR.sentinel")]


@active_if(PARAMS["run_singleR"])
@follows(seuratPCA, headstart)
@files(genSingleRjobs)
def singleR(infile, outfile):
    '''Perform cell identity prediction on a saved seurat object.
    The reference dataset is chosen by the user.

    The output consists of an rds object containing the prediction
    result ("predictions.rds") and a tsv file containing the predicted
    labels ("labels.tsv.gz")
    '''

    reference = os.path.basename(
        Path(outfile).parents[0]).replace(".ref.dir","")


    if PARAMS["headstart_singleR"]:

        spec, SPEC = TASK.get_vars(infile, outfile, PARAMS,
                                   make_outdir=True)

        source = os.path.join(PARAMS["headstart_path"],
                                     spec.sample_dir,
                              "singleR.dir",
                              reference + ".ref.dir")

        if os.path.exists(source):

            source_files = glob.glob(os.path.join(source,
                                                      "*"))

            for sf in [x for x in source_files if not x.endswith("singleR.sentinel")]:

                if os.path.exists(sf):
                    os.symlink(sf,
                               os.path.join(spec.sample_dir,
                                            "singleR.dir",
                                            reference + ".ref.dir",
                                            os.path.basename(sf)))

                else:
                    raise ValueError("Headstart singleR path not found")

            IOTools.touch_file(outfile)

    else:

        spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)


        # set the job threads and memory
        job_threads, job_memory, r_memory = TASK.get_resources(
            memory=PARAMS["resources_memory_extreme"],
            cpu=PARAMS["singleR_workers"])

        statement = '''Rscript %(tenx_dir)s/R/singleR_run.R
                           --seuratobject=%(infile)s
                           --reference=%(reference)s
                           --workers=%(singleR_workers)s
                           --outdir=%(outdir)s

                           &> %(log_file)s
                           ''' % dict(PARAMS, **SPEC, **locals())

        P.run(statement)
        IOTools.touch_file(outfile)

# Fix
@active_if(PARAMS["run_singleR"])
@transform(singleR,
           formatter("(.sentinel)$"),
           "{path[0]}/"
           "{basename[0]}.plot.sentinel")
def plotSingleR(infile, outfile):
    '''Make the singleR heatmap'''

    spec, SPEC = TASK.get_vars(infile, outfile, PARAMS)

    predictions = os.path.join(spec.indir,
                               "predictions.rds")

    # set the job threads and memory
    job_threads, job_memory, r_memory = TASK.get_resources(
        memory=PARAMS["resources_memory_standard"])

    statement = '''Rscript %(tenx_dir)s/R/singleR_plots.R
                       --seuratobject=%(seurat_object)s
                       --predictions=%(predictions)s
                       --outdir=%(outdir)s
                       --pdf=%(plot_pdf)s
                       &> %(log_file)s
                       ''' % dict(PARAMS, **SPEC, **locals())

    P.run(statement)
    IOTools.touch_file(outfile)




# ------------------------ < auxillary target > ----------------------------- #

@follows(aggregateUMIsPseudobulks)
def aux():
    pass

# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #


@follows()
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
