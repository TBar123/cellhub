'''
================
Pipeline Cell QC
================

Overview
========
This pipeline performs the following steps:
* Calculates per-cell QC metrics: ngenes, total_UMI, pct_mitochondrial,
  pct_ribosomal, pct_immunoglobin, pct_hemoglobin, and any specified geneset percentage
* Runs scrublet to calculate per-cell doublet score


Configuration
-------------
The pipeline requires a configured :file:`pipeline.yml` file.
Default configuration files can be generated by executing:
   python <srcdir>/pipeline_cell_qc.py config


Input files
-----------
A tsv file called 'libraries.tsv' is required.
This file must have column names as explained below.
Must not include row names.
Add as many rows as input channels/librarys for analysis.
This file must have the following columns:
* library_id - name used throughout. This could be the channel_pool id eg. A1
* path - path to the filtered_matrix folder from cellranger count


Dependencies
------------
This pipeline requires:
* cgat-core: https://github.com/cgat-developers/cgat-core
* R dependencies required in the r scripts


Pipeline output
===============
The pipeline returns:
* qcmetrics.dir folder with per-input qcmetrics.tsv.gz table
* scrublet.dir folder with per-input scrublet.tsv.gz table

Code
====

'''


from ruffus import *
from ruffus.combinatorics import *
import sys
import os
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools
from pathlib import Path
import pandas as pd

import tasks.control as C

# Override function to collect config files
P.control.write_config_files = C.write_config_files


# -------------------------- < parse parameters > --------------------------- #

# load options from the yml file
parameter_file = C.get_parameter_file(__file__, __name__)
PARAMS = P.get_parameters(parameter_file)

# Set the location of the cellhub code directory
if "code_dir" not in PARAMS.keys():
    PARAMS["code_dir"] = Path(__file__).parents[1]
else:
    if PARAMS["code_dir"] != Path(__file__).parents[1]:
        raise ValueError("Could not set the location of "
                         "the pipeline code directory")

# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))


# ########################################################################### #
# ######## Check input libraries file and that the input exists ############### #
# ########################################################################### #

@follows(mkdir("cell.qc.dir"))
@originate("cell.qc.dir/input.check.sentinel")
def checkInputs(outfile):
    '''Check that the input_libraries file exists and the path given in the file
       is a valid directorys. '''

    if not os.path.exists(PARAMS["input_libraries"]):
        raise ValueError('File specifying the input libraries is not present.'
                         'The file needs to be named PARAMS["input_libraries"] ')

    libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
    for filtered_matrix_path in libraries["filt_path"]:
        if not os.path.exists(filtered_matrix_path):
          raise ValueError('Input folder from cellranger run (outs/)'
                             ' does not exist.')
    IOTools.touch_file(outfile)

# ############################################# #
# ######## Calculate QC metrics ############### #
# ############################################# #


def qc_metrics_jobs():
    ''' Generate cluster jobs for each library '''

    if(__name__ == "__main__"):
        libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
        libraries.set_index("library_id", inplace=True)

        for library_name in libraries.index:
            out_library = library_name + ".tsv.gz"
            out_sentinel = "/".join(["cell.qc.dir/qcmetrics.dir", out_library])
            infile = None
            yield(infile, out_sentinel)

    else:
        yield(None, None)

@follows(mkdir("cell.qc.dir"),checkInputs)
@files(qc_metrics_jobs)
def calculate_qc_metrics(infile, outfile):
    '''This task will run R/calculate_qc_metrics.R,
    It uses the input_libraries.tsv to read the path to the cellranger directory for each input
    Ouput: creates a cell.qc.dir folder and a library_qcmetrics.tsv.gz table per library/channel
    For additional input files check the calculate_qc_metrics pipeline.yml sections:
    - Calculate the percentage of UMIs for genesets provided
    - Label barcodes as True/False based on whether they are part or not of a set of lists of barcodes provided
    '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)

    # Get cellranger directory and id
    library_name = outfile.split("/")[-1].replace(".tsv.gz", "")
    libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
    libraries.set_index("library_id", inplace=True)
    cellranger_dir = libraries.loc[library_name, "filt_path"]

    # Get genesets file
    if PARAMS["calculate_qc_metrics_geneset_file"] == "none" or PARAMS["calculate_qc_metrics_geneset_file"] == None:
      genesets_file = ""
    else:
      genesets_file = PARAMS["calculate_qc_metrics_geneset_file"]
      genesets_file = '''--genesets_file=%(genesets_file)s''' % locals()

    # Get file with files having barcodes to label as 'True' in output dataframe
    if PARAMS["calculate_qc_metrics_barcodes_to_label_as_True"] == "none" or PARAMS["calculate_qc_metrics_barcodes_to_label_as_True"] == None:
      barcodes_to_label_as_True = ""
    else:
      barcodes_to_label_as_True = PARAMS["calculate_qc_metrics_barcodes_to_label_as_True"]
      barcodes_to_label_as_True = '''--barcodes_to_label_as_True=%(barcodes_to_label_as_True)s''' % locals()

    # Other settings
    job_threads = PARAMS["resources_threads"]
    if ("G" in PARAMS["resources_job_memory"] or
        "M" in PARAMS["resources_job_memory"] ):
        job_memory = PARAMS["resources_job_memory"]

    log_file = outfile.replace(".tsv.gz", ".log")

    # Formulate and run statement
    statement = '''Rscript %(code_dir)s/R/calculate_qc_metrics.R
                 --cellranger_dir=%(cellranger_dir)s
                 --library_id=%(library_name)s
                 --numcores=%(job_threads)s
                 --log_filename=%(log_file)s
                 --outfile=%(outfile)s
                 %(genesets_file)s
                 %(barcodes_to_label_as_True)s
              '''
    P.run(statement)

    # Create sentinel file
    IOTools.touch_file(outfile)


def qc_reports_jobs():
    ''' Generate cluster jobs for each library '''

    if(__name__ == "__main__"):
        libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
        libraries.set_index("library_id", inplace=True)

        for library_name in libraries.index:
            out_library = "_".join([library_name, "qcmetrics_report.pdf"])
            out_sentinel = "/".join(["cell.qc.dir/reports", out_library])
            infile = libraries.loc[library_name]["filt_path"]
            yield(infile, out_sentinel)

    else:
        yield(None, None)


@follows(mkdir("cell.qc.dir/reports"), checkInputs)
@files(qc_reports_jobs)
def build_qc_reports(infile, outfile):
    '''This task will run R/build_qc_mapping_report.R,
    It expects three files in the input directory barcodes.tsv.gz,
    features.tsv.gz, and matrix.mtx.gz
    Ouput: creates a library_qcmetrics_report.pdf table per input folder
    '''
    # Get cellranger directory and id
    library_name = outfile.split("/")[-1].replace("_cell.qc.dir/reports", "")
    library_name = library_name.replace("_qcmetrics_report.pdf", "")

    # cellranger filtered output
    # cellranger_dir = "-".join([library_name, "count/outs/filtered_feature_bc_matrix"])

    # Other settings
    job_threads = PARAMS["resources_threads"]
    job_threads = PARAMS["resources_threads"]
    job_memory = "30G"

    log_file = outfile.replace(".pdf", ".log")

    # Formulate and run statement
    statement = '''Rscript %(code_dir)s/R/build_qc_mapping_reports.R
                --tenxfolder=%(infile)s
                --library_id=%(library_name)s
                --specie="hg"
                --outfolder="cell.qc.dir/reports"
                &> %(log_file)s
              '''
    P.run(statement)

# ############################################# #
# ######## Calculate doublet scores ########### #
# ############################################# #

@follows(checkInputs)
def qc_doublet_scoring_jobs():
    ''' Generate cluster jobs for each library '''

    if(__name__ == "__main__"):
        libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
        libraries.set_index("library_id", inplace=True)

        for library_name in libraries.index:
            out_library = library_name + ".sentinel"
            out_sentinel = "/".join(["cell.qc.dir/scrublet.dir", out_library])
            infile = None
            yield(infile, out_sentinel)

    else:
        yield(None, None)

@files(qc_doublet_scoring_jobs)
def run_scrublet(infile, outfile):
    '''This task will run python/run_scrublet.py,
    It uses the input_libraries.tsv to read the path to the cellranger directory for each input
    Ouput: creates a scrublet.dir folder and a library_scrublet.tsv.gz table per library/channel
    It also creates a doublet score histogram and a double score umap for each library/channel
    Check the scrublet section in the pipeline.yml to specify other parameters
    '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)

    # Get cellranger directory
    library_name = outfile.split("/")[-1].replace(".sentinel", "")
    libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
    libraries.set_index("library_id", inplace=True)
    cellranger_dir = libraries.loc[library_name, "filt_path"]

    if PARAMS["scrublet_subset"]:
        whitelist = libraries.loc[library_name, "whitelist"]
        subset_option = '''--keep_barcodes_file=%(whitelist)s''' %locals()
    else:
        subset_option = ''' '''

    # Scrublet parameters
    expected_doublet_rate = PARAMS["scrublet_expected_doublet_rate"]
    min_counts = PARAMS["scrublet_min_counts"]
    min_cells = PARAMS["scrublet_min_cells"]
    min_gene_variability_pctl = PARAMS["scrublet_min_gene_variability_pctl"]
    n_prin_comps = PARAMS["scrublet_n_prin_comps"]

    # Other settings
    job_threads = PARAMS["resources_threads"]
    if ("G" in PARAMS["resources_job_memory"] or
        "M" in PARAMS["resources_job_memory"] ):
        job_memory = PARAMS["resources_job_memory"]

    job_threads=3
    job_memory="50G"
    log_file = outfile.replace(".sentinel", ".log")
    outdir = Path(outfile).parent

    # Formulate and run statement
    statement = '''python %(code_dir)s/python/run_scrublet.py
                   --cellranger_dir=%(cellranger_dir)s
                   %(subset_option)s
                   --library_id=%(library_name)s
                   --expected_doublet_rate=%(expected_doublet_rate)s
                   --min_counts=%(min_counts)s
                   --min_cells=%(min_cells)s
                   --min_gene_variability_pctl=%(min_gene_variability_pctl)s
                   --n_prin_comps=%(n_prin_comps)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    # Create sentinel file
    IOTools.touch_file(outfile)


# ---------------------------------------------------
# Generic pipeline tasks

@follows(mkdir("cell.qc.dir"))
@files(None, "cell.qc.dir/plot.sentinel")
def plot(infile, outfile):
    '''Draw the pipeline flowchart'''

    pipeline_printout_graph ( "cell.qc.dir/pipeline_flowchart.svg",
                          "svg",
                          [full],
                          no_key_legend=True)

    pipeline_printout_graph ( "cell.qc.dir/pipeline_flowchart.png",
                          "png",
                          [full],
                          no_key_legend=True)

    IOTools.touch_file(outfile)


@follows(calculate_qc_metrics, build_qc_reports, run_scrublet, plot)
def full():
    '''
    Run the full pipeline.
    '''
    pass


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
