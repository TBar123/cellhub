"""
===================
Pipeline Emptydrops
===================

Overview
========

This pipeline performs the following task:

* run emptydrops on the raw output of cellranger

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_emptydrops.py config


Input files
-----------

The pipeline is run from the cellranger count output (raw_feature_bc_matrix folder).

The pipeline expects a tsv file containing a column named path and a column named
sample_id.

'raw path' should contain the path to each cellranger path to raw_feature_bc_matrix.
'sample_id' is the desired name for each sample (output folder will be named like this).


Dependencies
------------

This pipeline requires:
* cgat-core: https://github.com/cgat-developers/cgat-core
* R + packages

Pipeline output
===============

The pipeline returns:
A list of barcodes passing emptydrops cell identification and a table with
barcode ranks including all barcodes (this can be used for knee plots).


Code
====

"""
from ruffus import *
from pathlib import Path
import sys
import os
import yaml
import cgatcore.experiment as E
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools
import pandas as pd

import tasks.control as C

# Override function to collect config files
P.control.write_config_files = C.write_config_files


# -------------------------- < parse parameters > --------------------------- #

# load options from the yml file
parameter_file = C.get_parameter_file(__file__, __name__)
PARAMS = P.get_parameters(parameter_file)

# set the location of the tenx code directory
PARAMS["code_dir"] = Path(__file__).parents[1]


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))


# ########################################################################### #
# ######## Check input libraries file and that the input exists ############### #
# ########################################################################### #

@follows(mkdir("emptydrops.dir"))
@originate("emptydrops.dir/input.check.sentinel")
def checkInputs(outfile):
    '''Check that input_libraries.tsv exists and the path given in the file
       is a valid directorys. '''

    if not os.path.exists(PARAMS["input_libraries"]):
        raise ValueError('File specifying the input libraries is not present.'
                         'The file needs to be named PARAMS["input_libraries"] ')

    libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
    for p in libraries["raw_path"]:
        print(p)
        if not os.path.exists(p):
            raise ValueError('Input folder from cellranger run raw mtx matrices'
                             ' does not exist.')
    IOTools.touch_file(outfile)


def genClusterJobs():
    ''' Generate cluster jobs for each library '''
    libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
    infile = None
    libraries.set_index("library_id", inplace=True)

    for library_name in libraries.index:
        library_dir = library_name + ".library.dir"
        out_sentinel = os.path.join("emptydrops.dir", library_dir, "emptyDrops.sentinel")
        yield(infile, out_sentinel)


# ########################################################################### #
# ########################## Run EmptyDrops ################################# #
# ########################################################################### #

@follows(checkInputs)
@files(genClusterJobs)
def runEmptyDrops(infile, outfile):
    ''' Run Rscript to run EmptyDrops on each library '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    options = {}
    options["FDR"] = float(PARAMS["emptydrops_FDR"])

    library_name = outfile.split("/")[1][:-len(".library.dir")]
    options["outdir"] = outdir

    libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
    libraries.set_index("library_id", inplace=True)

    options["cellrangerDir"] = libraries.loc[library_name ,"raw_path"]

    # # remove blacklisted cells if required
    # if 'blacklist' in libraries.columns:
    #     options["blacklist"] = libraries.loc[library_name, "blacklist"]

    log_file = outfile.replace("sentinel","log")
    job_threads = PARAMS["emptydrops_slots"]
    if ("G" in PARAMS["emptydrops_memory"] or
    "M" in PARAMS["emptydrops_memory"] ):
        job_memory = PARAMS["emptydrops_memory"]

    task_yaml_file = os.path.abspath(os.path.join(outdir, "emptydrops.yml"))
    with open(task_yaml_file, 'w') as yaml_file:
        yaml.dump(options, yaml_file)

    statement = '''Rscript %(code_dir)s/R/run_emptydrops.R
                   --task_yml=%(task_yaml_file)s
                   --log_filename=%(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


def genClusterJobsMeans():
    ''' Generate cluster jobs for each library '''
    libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
    infile = None
    libraries.set_index("library_id", inplace=True)

    for library_name in libraries.index:
        library_dir = library_name + ".library.dir"
        out_sentinel = os.path.join("emptydrops.dir", library_dir, "meanReads.sentinel")
        yield(infile, out_sentinel)


@follows(checkInputs)
@files(genClusterJobsMeans)
def calculateMeanReadsPerCell(infile, outfile):
    ''' Calculate the mean reads per cell '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    options = {}
    library_name = outfile.split("/")[1][:-len(".library.dir")]
    options["outdir"] = outdir

    libraries = pd.read_csv(PARAMS["input_libraries"], sep='\t')
    libraries.set_index("library_id", inplace=True)
    options["cellrangerDir"] = libraries.loc[library_name ,"raw_path"]

    log_file = outfile.replace("sentinel","log")
    job_threads = PARAMS["emptydrops_slots"]
    if ("G" in PARAMS["emptydrops_memory"] or
    "M" in PARAMS["emptydrops_memory"] ):
        job_memory = PARAMS["emptydrops_memory"]

    task_yaml_file = os.path.abspath(os.path.join(outdir, "calculate_mean_reads.yml"))
    with open(task_yaml_file, 'w') as yaml_file:
        yaml.dump(options, yaml_file)

    statement = '''Rscript %(code_dir)s/R/calculate_mean_reads.R
                   --task_yml=%(task_yaml_file)s
                   --log_filename=%(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ---------------------------------------------------
# Generic pipeline tasks

@follows(runEmptyDrops, calculateMeanReadsPerCell)
def full():
    '''
    Run the full pipeline.
    '''
    pass


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
